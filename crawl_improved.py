"""
æ”¹è¿›ç‰ˆå¾®åšçˆ¬è™« - ä½¿ç”¨å¤šç§æ–¹æ³•è·å–å…³æ³¨åˆ—è¡¨
"""

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import time
import json
from pathlib import Path
from tqdm import tqdm
import logging
import re

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ImprovedWeiboCrawler:
    """æ”¹è¿›ç‰ˆå¾®åšçˆ¬è™«"""
    
    def __init__(self, headless=False):
        logger.info("æ­£åœ¨å¯åŠ¨Chromeæµè§ˆå™¨...")
        
        chrome_options = Options()
        
        if headless:
            chrome_options.add_argument('--headless')
        
        # åçˆ¬è™«è®¾ç½®
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        # æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨
        chrome_options.add_argument('user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36')
        
        self.driver = webdriver.Chrome(options=chrome_options)
        self.wait = WebDriverWait(self.driver, 10)
        
        # ç§»é™¤webdriveræ ‡è¯†
        self.driver.execute_cdp_cmd('Page.addScriptToEvaluateOnNewDocument', {
            'source': '''
                Object.defineProperty(navigator, 'webdriver', {
                    get: () => undefined
                })
            '''
        })
        
        logger.info("âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸ!")
    
    def manual_login(self):
        """æ‰‹åŠ¨ç™»å½•"""
        logger.info("è¯·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨ç™»å½•å¾®åš...")
        
        self.driver.get('https://weibo.com/')
        time.sleep(2)
        
        print("\n" + "="*70)
        print("è¯·åœ¨æ‰“å¼€çš„æµè§ˆå™¨çª—å£ä¸­:")
        print("  1. ç‚¹å‡»ç™»å½•æŒ‰é’®")
        print("  2. è¾“å…¥è´¦å·å¯†ç ")
        print("  3. å®Œæˆç™»å½•ï¼ˆåŒ…æ‹¬æ»‘å—éªŒè¯ç­‰ï¼‰")
        print("  4. çœ‹åˆ°å¾®åšé¦–é¡µå")
        print("="*70)
        
        input("\nç™»å½•å®Œæˆåï¼ŒæŒ‰å›è½¦é”®ç»§ç»­...")
        
        logger.info("âœ… ç»§ç»­æ‰§è¡Œ...")
        return True
    
    def get_user_info(self, uid: str) -> dict:
        """è·å–ç”¨æˆ·ä¿¡æ¯"""
        url = f'https://weibo.com/u/{uid}'
        
        try:
            self.driver.get(url)
            time.sleep(3)
            
            # è·å–æ˜µç§°
            try:
                nickname = self.driver.find_element(By.CSS_SELECTOR, '[class*="head_nick"]').text
            except:
                nickname = self.driver.title.split('-')[0].strip() if '-' in self.driver.title else f'user_{uid}'
            
            logger.info(f"âœ… è·å–ç”¨æˆ·: {nickname}")
            
            return {
                'uid': uid,
                'screen_name': nickname,
                'followers_count': 0,
                'follow_count': 0,
                'description': ''
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç”¨æˆ· {uid} å¤±è´¥: {e}")
            return None
    
    def get_followings_method1(self, uid: str, max_count: int = 50) -> list:
        """æ–¹æ³•1: ä»å…³æ³¨é¡µé¢ç›´æ¥è§£æ"""
        followings = []
        
        url = f'https://weibo.com/u/{uid}/follow'
        logger.info(f"  æ–¹æ³•1: è®¿é—®å…³æ³¨é¡µé¢ {url}")
        
        try:
            self.driver.get(url)
            time.sleep(3)
            
            # å°è¯•å¤šæ¬¡æ»šåŠ¨åŠ è½½
            for i in range(5):
                # æ»šåŠ¨åˆ°åº•éƒ¨
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)
                
                # æŸ¥æ‰¾æ‰€æœ‰ç”¨æˆ·é“¾æ¥
                try:
                    # å°è¯•ä¸åŒçš„é€‰æ‹©å™¨
                    selectors = [
                        'a[href*="/u/"]',
                        'a[href*="/profile/"]',
                        '[class*="card"] a[href*="/u/"]'
                    ]
                    
                    for selector in selectors:
                        links = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        
                        for link in links:
                            try:
                                href = link.get_attribute('href')
                                if href and '/u/' in href:
                                    # æå–UID
                                    match = re.search(r'/u/(\d+)', href)
                                    if match:
                                        following_uid = match.group(1)
                                        if following_uid != uid and following_uid not in followings:
                                            followings.append(following_uid)
                                            
                                            if len(followings) >= max_count:
                                                logger.info(f"  âœ… æ–¹æ³•1è·å–åˆ° {len(followings)} ä¸ªç”¨æˆ·")
                                                return followings
                            except:
                                continue
                    
                    if len(followings) > 0:
                        logger.info(f"  å·²è·å– {len(followings)} ä¸ªç”¨æˆ·...")
                
                except Exception as e:
                    logger.debug(f"  æ»šåŠ¨ {i+1} å‡ºé”™: {e}")
                    continue
            
            logger.info(f"  æ–¹æ³•1è·å–åˆ° {len(followings)} ä¸ªç”¨æˆ·")
            return followings
            
        except Exception as e:
            logger.error(f"  æ–¹æ³•1å¤±è´¥: {e}")
            return []
    
    def get_followings_method2(self, uid: str, max_count: int = 50) -> list:
        """æ–¹æ³•2: ä½¿ç”¨ç§»åŠ¨ç«¯é¡µé¢"""
        followings = []
        
        url = f'https://m.weibo.cn/u/{uid}'
        logger.info(f"  æ–¹æ³•2: è®¿é—®ç§»åŠ¨ç«¯ {url}")
        
        try:
            # ä¸´æ—¶åˆ‡æ¢åˆ°ç§»åŠ¨ç«¯UA
            self.driver.execute_cdp_cmd('Network.setUserAgentOverride', {
                "userAgent": 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X)'
            })
            
            self.driver.get(url)
            time.sleep(3)
            
            # æŸ¥æ‰¾å…³æ³¨æŒ‰é’®å¹¶ç‚¹å‡»
            try:
                follow_buttons = self.driver.find_elements(By.XPATH, "//*[contains(text(), 'å…³æ³¨')]")
                if follow_buttons:
                    follow_buttons[0].click()
                    time.sleep(2)
            except:
                pass
            
            # è§£æç”¨æˆ·åˆ—è¡¨
            for i in range(3):
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)
                
                # æŸ¥æ‰¾ç”¨æˆ·å¡ç‰‡
                try:
                    cards = self.driver.find_elements(By.CSS_SELECTOR, '[class*="card"]')
                    for card in cards:
                        try:
                            links = card.find_elements(By.TAG_NAME, 'a')
                            for link in links:
                                href = link.get_attribute('href')
                                if href and '/u/' in href:
                                    match = re.search(r'/u/(\d+)', href)
                                    if match:
                                        following_uid = match.group(1)
                                        if following_uid != uid and following_uid not in followings:
                                            followings.append(following_uid)
                        except:
                            continue
                except:
                    pass
            
            # æ¢å¤PC UA
            self.driver.execute_cdp_cmd('Network.setUserAgentOverride', {
                "userAgent": 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
            })
            
            logger.info(f"  æ–¹æ³•2è·å–åˆ° {len(followings)} ä¸ªç”¨æˆ·")
            return followings[:max_count]
            
        except Exception as e:
            logger.error(f"  æ–¹æ³•2å¤±è´¥: {e}")
            return []
    
    def get_followings_method3(self, uid: str, max_count: int = 50) -> list:
        """æ–¹æ³•3: ä»ç”¨æˆ·ä¸»é¡µæå–äº’åŠ¨ç”¨æˆ·"""
        followings = []
        
        url = f'https://weibo.com/u/{uid}'
        logger.info(f"  æ–¹æ³•3: ä»ä¸»é¡µæå–äº’åŠ¨ç”¨æˆ·")
        
        try:
            self.driver.get(url)
            time.sleep(3)
            
            # æ»šåŠ¨åŠ è½½å¾®åš
            for i in range(10):
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(1.5)
                
                # æŸ¥æ‰¾æ‰€æœ‰@ç”¨æˆ· å’Œ è½¬å‘ç”¨æˆ·
                try:
                    # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«ç”¨æˆ·é“¾æ¥çš„å…ƒç´ 
                    all_links = self.driver.find_elements(By.CSS_SELECTOR, 'a[href*="/u/"], a[href*="/n/"]')
                    
                    for link in all_links:
                        try:
                            href = link.get_attribute('href')
                            if href and '/u/' in href:
                                match = re.search(r'/u/(\d+)', href)
                                if match:
                                    other_uid = match.group(1)
                                    if other_uid != uid and other_uid not in followings:
                                        followings.append(other_uid)
                                        
                                        if len(followings) >= max_count:
                                            logger.info(f"  âœ… æ–¹æ³•3è·å–åˆ° {len(followings)} ä¸ªç”¨æˆ·")
                                            return followings
                        except:
                            continue
                
                except Exception as e:
                    continue
            
            logger.info(f"  æ–¹æ³•3è·å–åˆ° {len(followings)} ä¸ªç”¨æˆ·")
            return followings
            
        except Exception as e:
            logger.error(f"  æ–¹æ³•3å¤±è´¥: {e}")
            return []
    
    def get_followings(self, uid: str, max_count: int = 50) -> list:
        """è·å–å…³æ³¨åˆ—è¡¨ - å°è¯•æ‰€æœ‰æ–¹æ³•"""
        logger.info(f"æ­£åœ¨è·å–ç”¨æˆ· {uid} çš„å…³æ³¨åˆ—è¡¨...")
        
        # ä¾æ¬¡å°è¯•3ç§æ–¹æ³•
        all_followings = []
        
        # æ–¹æ³•1: ä»å…³æ³¨é¡µé¢
        followings1 = self.get_followings_method1(uid, max_count)
        all_followings.extend(followings1)
        
        if len(all_followings) >= max_count:
            logger.info(f"âœ… å…±è·å– {len(all_followings[:max_count])} ä¸ªå…³æ³¨ç”¨æˆ·")
            return all_followings[:max_count]
        
        # æ–¹æ³•2: ç§»åŠ¨ç«¯
        followings2 = self.get_followings_method2(uid, max_count - len(all_followings))
        all_followings.extend([f for f in followings2 if f not in all_followings])
        
        if len(all_followings) >= max_count:
            logger.info(f"âœ… å…±è·å– {len(all_followings[:max_count])} ä¸ªå…³æ³¨ç”¨æˆ·")
            return all_followings[:max_count]
        
        # æ–¹æ³•3: ä»ä¸»é¡µäº’åŠ¨ç”¨æˆ·
        followings3 = self.get_followings_method3(uid, max_count - len(all_followings))
        all_followings.extend([f for f in followings3 if f not in all_followings])
        
        # å»é‡
        all_followings = list(set(all_followings))
        
        logger.info(f"âœ… å…±è·å– {len(all_followings)} ä¸ªå…³æ³¨ç”¨æˆ·ï¼ˆç»„åˆ3ç§æ–¹æ³•ï¼‰")
        return all_followings[:max_count]
    
    def crawl_network(self, start_uid: str, max_users: int = 200, 
                     max_depth: int = 2, delay: float = 3.0) -> dict:
        """BFSçˆ¬å–ç¤¾äº¤ç½‘ç»œ"""
        users = {}
        edges = []
        visited = set()
        queue = [(start_uid, 0)]
        
        pbar = tqdm(total=max_users, desc="çˆ¬å–å¾®åšç”¨æˆ·")
        
        while queue and len(users) < max_users:
            uid, depth = queue.pop(0)
            
            if uid in visited or depth > max_depth:
                continue
            
            visited.add(uid)
            
            # è·å–ç”¨æˆ·ä¿¡æ¯
            user_info = self.get_user_info(uid)
            if not user_info:
                logger.warning(f"è·³è¿‡ç”¨æˆ· {uid}")
                continue
            
            users[uid] = user_info
            pbar.update(1)
            
            time.sleep(delay)
            
            # è·å–å…³æ³¨åˆ—è¡¨
            if depth < max_depth:
                followings = self.get_followings(uid, max_count=20)
                
                for following_uid in followings:
                    edges.append((uid, following_uid))
                    
                    if following_uid not in visited and len(users) < max_users:
                        queue.append((following_uid, depth + 1))
                
                time.sleep(delay)
        
        pbar.close()
        
        return {
            'users': users,
            'edges': edges,
            'metadata': {
                'start_uid': start_uid,
                'max_depth': max_depth,
                'total_users': len(users),
                'total_edges': len(edges)
            }
        }
    
    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.driver:
            self.driver.quit()
            logger.info("æµè§ˆå™¨å·²å…³é—­")


def main():
    print("="*70)
    print("æ”¹è¿›ç‰ˆå¾®åšçˆ¬è™« - ä½¿ç”¨å¤šç§æ–¹æ³•è·å–å…³æ³¨åˆ—è¡¨")
    print("="*70)
    
    # é…ç½®
    start_uid = input("\nè¯·è¾“å…¥èµ·å§‹ç”¨æˆ·UIDï¼ˆç›´æ¥å›è½¦ä½¿ç”¨'äººæ°‘æ—¥æŠ¥'ï¼‰: ").strip()
    if not start_uid:
        start_uid = "2803301701"
        tqdm.write(f"ä½¿ç”¨é»˜è®¤: äººæ°‘æ—¥æŠ¥ ({start_uid})")
    
    max_users_input = input("\nçˆ¬å–å¤šå°‘ä¸ªç”¨æˆ·ï¼Ÿï¼ˆç›´æ¥å›è½¦ä½¿ç”¨200ï¼‰: ").strip()
    max_users = int(max_users_input) if max_users_input else 200
    
    show_browser = input("\næ˜¯å¦æ˜¾ç¤ºæµè§ˆå™¨çª—å£ï¼Ÿ(y/nï¼Œé»˜è®¤y): ").strip().lower()
    headless = (show_browser == 'n')
    
    # åˆ›å»ºçˆ¬è™«
    try:
        crawler = ImprovedWeiboCrawler(headless=headless)
        
        # æ‰‹åŠ¨ç™»å½•
        crawler.manual_login()
        
        # å¼€å§‹çˆ¬å–
        print("\n" + "="*70)
        print("å¼€å§‹çˆ¬å–ç¤¾äº¤ç½‘ç»œ")
        print("="*70)
        print(f"èµ·å§‹ç”¨æˆ·: {start_uid}")
        print(f"ç›®æ ‡æ•°é‡: {max_users} ä¸ªç”¨æˆ·")
        print("\nâš ï¸  è¯·ä¸è¦å…³é—­æµè§ˆå™¨çª—å£!\n")
        
        data = crawler.crawl_network(
            start_uid=start_uid,
            max_users=max_users,
            max_depth=2,
            delay=3.0
        )
        
        # ä¿å­˜æ•°æ®
        output_path = Path('data/raw/weibo_improved_data.json')
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print("\n" + "="*70)
        print("ğŸ‰ çˆ¬å–å®Œæˆ!")
        print("="*70)
        print(f"ç”¨æˆ·æ•°: {data['metadata']['total_users']}")
        print(f"å…³ç³»æ•°: {data['metadata']['total_edges']}")
        print(f"æ•°æ®æ–‡ä»¶: {output_path}")
        
        crawler.close()
        
        if data['metadata']['total_edges'] > 0:
            tqdm.write("\nâœ… æˆåŠŸè·å–åˆ°å…³æ³¨å…³ç³»ï¼")
            tqdm.write("\nä¸‹ä¸€æ­¥:")
            tqdm.write(f"  1. python step2_build_graph.py --input {output_path}")
            tqdm.write("  2. python step3_anonymize.py")
            tqdm.write("  3. python step4_attack.py")
        else:
            tqdm.write("\nâš ï¸  æœªè·å–åˆ°å…³æ³¨å…³ç³»")
            tqdm.write("å¯èƒ½åŸå› ï¼š")
            tqdm.write("  1. æœªæ­£ç¡®ç™»å½•")
            tqdm.write("  2. è¯¥ç”¨æˆ·æ²¡æœ‰å…¬å¼€çš„å…³æ³¨åˆ—è¡¨")
            tqdm.write("  3. é¡µé¢ç»“æ„å˜åŒ–")
            tqdm.write("\nå»ºè®®: å°è¯•ä½¿ç”¨ä½ è‡ªå·±çš„å¾®åšè´¦å·UID")
        
    except Exception as e:
        logger.error(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        try:
            crawler.close()
        except:
            pass


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­")

