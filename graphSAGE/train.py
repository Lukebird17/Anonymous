import torch
import torch.nn.functional as F
import torch.optim as optim
import time
from pathlib import Path

from config import Config
from dataloader import GraphLoader
from network import GraphSAGE


class Trainer:
    def __init__(self):
        self.cfg = Config()
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ğŸš€ ä½¿ç”¨è®¾å¤‡: {self.device}")

        self._prepare_data()
        self._build_model()
        self.optimizer = optim.Adam(
            self.model.parameters(),
            lr=self.cfg.LEARNING_RATE
        )

    def _prepare_data(self):
        """å†…éƒ¨æ–¹æ³•: åŠ è½½å¹¶å¤„ç†æ•°æ®åˆ°æŒ‡å®šè®¾å¤‡"""
        print("\n[Data] æ­£åœ¨åŠ è½½æ•°æ®...")
        loader = GraphLoader()
        data_orig, data_anon, train_pairs, test_pairs = loader.load()

        self.data_orig = data_orig.to(self.device)
        self.data_anon = data_anon.to(self.device)
        self.train_pairs = train_pairs.to(self.device)
        self.test_pairs = test_pairs.to(self.device)

        print(f"[Data] æ•°æ®åŠ è½½å®Œæ¯•. èŠ‚ç‚¹ç‰¹å¾ç»´åº¦: {self.data_orig.x.shape[1]}")

    def _build_model(self):
        """å†…éƒ¨æ–¹æ³•: æ„å»ºæ¨¡å‹"""
        input_dim = self.data_orig.x.shape[1]

        self.model = GraphSAGE(
            in_dim=input_dim,
            hidden_dim=self.cfg.HIDDEN_DIM,
            out_dim=self.cfg.OUTPUT_DIM,
            dropout=self.cfg.DROPOUT
        ).to(self.device)

        print(f"[Model] æ¨¡å‹å·²æ„å»º: Input={input_dim}, Hidden={self.cfg.HIDDEN_DIM}, Out={self.cfg.OUTPUT_DIM}")

    def _compute_loss(self, emb_orig, emb_anon):
        """
        è®¡ç®—æŸå¤±å‡½æ•°
        è¿™é‡Œç›®å‰ä½¿ç”¨ MSE Loss (æœ€å°åŒ–æ­£æ ·æœ¬è·ç¦»)=
        """
        seed_emb_orig = emb_orig[self.train_pairs[:, 0]]
        seed_emb_anon = emb_anon[self.train_pairs[:, 1]]

        loss = F.mse_loss(seed_emb_orig, seed_emb_anon)
        return loss

    def train_epoch(self):
        self.model.train()
        self.optimizer.zero_grad()

        emb_orig, emb_anon = self.model(self.data_orig, self.data_anon)

        loss = self._compute_loss(emb_orig, emb_anon)

        loss.backward()
        self.optimizer.step()

        return loss.item()

    def fit(self):
        print(f"\n[Train] å¼€å§‹è®­ç»ƒï¼Œå…± {self.cfg.EPOCHS} ä¸ª Epochs...")
        start_time = time.time()

        try:
            for epoch in range(1, self.cfg.EPOCHS + 1):
                loss = self.train_epoch()

                # æ‰“å°æ—¥å¿— (æ¯10è½®æˆ–ç¬¬ä¸€è½®)
                if epoch == 1 or epoch % 10 == 0:
                    print(f"Epoch {epoch:03d}/{self.cfg.EPOCHS} | Loss: {loss:.6f}")

        except KeyboardInterrupt:
            print("\nâš ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")

        end_time = time.time()
        print(f"\n[Train] è®­ç»ƒç»“æŸ. æ€»è€—æ—¶: {end_time - start_time:.2f}s")
        self.save_model()

    def save_model(self):
        """ä¿å­˜æ¨¡å‹çŠ¶æ€"""
        save_path = self.cfg.MODEL_SAVE_PATH
        save_path.parent.mkdir(parents=True, exist_ok=True)

        torch.save(self.model.state_dict(), save_path)
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜è‡³: {save_path}")


def main():
    trainer = Trainer()
    trainer.fit()


if __name__ == "__main__":
    main()