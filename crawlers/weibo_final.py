"""
å¾®åšçˆ¬è™« - æœ€ç»ˆç‰ˆæœ¬
ä½¿ç”¨å¤šç§æ–¹æ³•ç¡®ä¿èƒ½çˆ¬åˆ°çœŸå®æ•°æ®
"""

import requests
import json
import time
from pathlib import Path
from tqdm import tqdm
import logging
import re

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RobustWeiboCrawler:
    """å¼ºåŠ›å¾®åšçˆ¬è™« - å¤šç§å¤‡ç”¨æ–¹æ¡ˆ"""
    
    def __init__(self, cookies: str):
        self.session = requests.Session()
        self.cookies_dict = self._parse_cookies(cookies)
        
        # è®¾ç½®å®Œæ•´çš„è¯·æ±‚å¤´ï¼ˆæ¨¡æ‹ŸçœŸå®æµè§ˆå™¨ï¼‰
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Referer': 'https://weibo.com/',
            'X-Requested-With': 'XMLHttpRequest',
            'Sec-Fetch-Dest': 'empty',
            'Sec-Fetch-Mode': 'cors',
            'Sec-Fetch-Site': 'same-origin',
        })
        
        # è®¾ç½®cookies
        for name, value in self.cookies_dict.items():
            self.session.cookies.set(name, value, domain='.weibo.com')
            self.session.cookies.set(name, value, domain='.weibo.cn')
    
    def _parse_cookies(self, cookie_str: str) -> dict:
        """è§£æCookie"""
        cookies = {}
        for item in cookie_str.split('; '):
            if '=' in item:
                key, value = item.split('=', 1)
                cookies[key.strip()] = value.strip()
        return cookies
    
    def get_user_info_method1(self, uid: str) -> dict:
        """æ–¹æ³•1: PCç«¯API"""
        url = f'https://weibo.com/ajax/profile/info?uid={uid}'
        
        try:
            response = self.session.get(url, timeout=10)
            if response.status_code == 200:
                data = response.json()
                if data.get('ok') == 1 and 'data' in data:
                    user = data['data'].get('user', {})
                    if user.get('screen_name'):
                        logger.info(f"âœ… æ–¹æ³•1æˆåŠŸè·å–ç”¨æˆ·: {user.get('screen_name')}")
                        return {
                            'uid': uid,
                            'screen_name': user.get('screen_name', ''),
                            'followers_count': user.get('followers_count', 0),
                            'follow_count': user.get('follow_count', 0),
                            'description': user.get('description', ''),
                        }
        except Exception as e:
            logger.debug(f"æ–¹æ³•1å¤±è´¥: {e}")
        
        return None
    
    def get_user_info_method2(self, uid: str) -> dict:
        """æ–¹æ³•2: ç§»åŠ¨ç«¯API"""
        url = f'https://m.weibo.cn/api/container/getIndex?type=uid&value={uid}'
        
        try:
            # ä¸´æ—¶ä¿®æ”¹UAä¸ºç§»åŠ¨ç«¯
            old_ua = self.session.headers.get('User-Agent')
            self.session.headers['User-Agent'] = 'Mozilla/5.0 (iPhone; CPU iPhone OS 14_0 like Mac OS X)'
            
            response = self.session.get(url, timeout=10)
            
            # æ¢å¤UA
            self.session.headers['User-Agent'] = old_ua
            
            if response.status_code == 200:
                data = response.json()
                if data.get('ok') == 1:
                    user = data.get('data', {}).get('userInfo', {})
                    if user.get('screen_name'):
                        logger.info(f"âœ… æ–¹æ³•2æˆåŠŸè·å–ç”¨æˆ·: {user.get('screen_name')}")
                        return {
                            'uid': uid,
                            'screen_name': user.get('screen_name', ''),
                            'followers_count': user.get('followers_count', 0),
                            'follow_count': user.get('follow_count', 0),
                            'description': user.get('description', ''),
                        }
        except Exception as e:
            logger.debug(f"æ–¹æ³•2å¤±è´¥: {e}")
        
        return None
    
    def get_user_info_method3(self, uid: str) -> dict:
        """æ–¹æ³•3: ç›´æ¥è®¿é—®ç”¨æˆ·ä¸»é¡µHTMLè§£æ"""
        url = f'https://weibo.com/u/{uid}'
        
        try:
            response = self.session.get(url, timeout=10)
            if response.status_code == 200:
                html = response.text
                
                # å°è¯•ä»HTMLä¸­æå–ç”¨æˆ·ä¿¡æ¯
                # æŸ¥æ‰¾$render_data
                match = re.search(r'\$render_data\s*=\s*(\[.*?\])\[0\]', html, re.DOTALL)
                if match:
                    try:
                        data_str = match.group(1)
                        data = json.loads(data_str)
                        if data and len(data) > 0:
                            user_data = data[0]
                            status = user_data.get('status', {})
                            user = status.get('user', {})
                            
                            if user.get('screen_name'):
                                logger.info(f"âœ… æ–¹æ³•3æˆåŠŸè·å–ç”¨æˆ·: {user.get('screen_name')}")
                                return {
                                    'uid': uid,
                                    'screen_name': user.get('screen_name', ''),
                                    'followers_count': user.get('followers_count', 0),
                                    'follow_count': user.get('friends_count', 0),
                                    'description': user.get('description', ''),
                                }
                    except:
                        pass
        except Exception as e:
            logger.debug(f"æ–¹æ³•3å¤±è´¥: {e}")
        
        return None
    
    def get_user_info(self, uid: str) -> dict:
        """è·å–ç”¨æˆ·ä¿¡æ¯ - å°è¯•æ‰€æœ‰æ–¹æ³•"""
        logger.info(f"è·å–ç”¨æˆ· {uid} ä¿¡æ¯...")
        
        # ä¾æ¬¡å°è¯•3ç§æ–¹æ³•
        for method in [self.get_user_info_method1, 
                      self.get_user_info_method2,
                      self.get_user_info_method3]:
            result = method(uid)
            if result:
                return result
            time.sleep(1)  # æ–¹æ³•ä¹‹é—´å»¶è¿Ÿ
        
        logger.warning(f"âŒ æ‰€æœ‰æ–¹æ³•éƒ½æ— æ³•è·å–ç”¨æˆ· {uid}")
        return None
    
    def get_followings(self, uid: str, max_count: int = 50) -> list:
        """è·å–å…³æ³¨åˆ—è¡¨"""
        followings = []
        page = 1
        
        logger.info(f"è·å–ç”¨æˆ· {uid} çš„å…³æ³¨åˆ—è¡¨...")
        
        while len(followings) < max_count and page <= 5:
            # PCç«¯å…³æ³¨API
            url = f'https://weibo.com/ajax/friendships/friends?uid={uid}&page={page}'
            
            try:
                time.sleep(2)  # é‡è¦å»¶è¿Ÿ
                response = self.session.get(url, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    if data.get('ok') == 1:
                        users = data.get('data', {}).get('users', [])
                        
                        if not users:
                            break
                        
                        for user in users:
                            if 'idstr' in user:
                                followings.append(user['idstr'])
                        
                        logger.info(f"  ç¬¬{page}é¡µ: è·å–åˆ° {len(users)} ä¸ªç”¨æˆ·")
                        page += 1
                    else:
                        logger.warning(f"  APIè¿”å›é”™è¯¯: {data.get('msg', 'Unknown')}")
                        break
                else:
                    logger.warning(f"  HTTPé”™è¯¯: {response.status_code}")
                    break
                    
            except Exception as e:
                logger.error(f"  è·å–å…³æ³¨åˆ—è¡¨å¤±è´¥: {e}")
                break
        
        logger.info(f"  å…±è·å– {len(followings)} ä¸ªå…³æ³¨ç”¨æˆ·")
        return followings[:max_count]
    
    def get_followers(self, uid: str, max_count: int = 50) -> list:
        """è·å–ç²‰ä¸åˆ—è¡¨"""
        followers = []
        page = 1
        
        logger.info(f"è·å–ç”¨æˆ· {uid} çš„ç²‰ä¸åˆ—è¡¨...")
        
        while len(followers) < max_count and page <= 5:
            url = f'https://weibo.com/ajax/friendships/followers?uid={uid}&page={page}'
            
            try:
                time.sleep(2)
                response = self.session.get(url, timeout=10)
                
                if response.status_code == 200:
                    data = response.json()
                    
                    if data.get('ok') == 1:
                        users = data.get('data', {}).get('users', [])
                        
                        if not users:
                            break
                        
                        for user in users:
                            if 'idstr' in user:
                                followers.append(user['idstr'])
                        
                        logger.info(f"  ç¬¬{page}é¡µ: è·å–åˆ° {len(users)} ä¸ªç²‰ä¸")
                        page += 1
                    else:
                        break
                else:
                    break
                    
            except Exception as e:
                logger.error(f"  è·å–ç²‰ä¸åˆ—è¡¨å¤±è´¥: {e}")
                break
        
        logger.info(f"  å…±è·å– {len(followers)} ä¸ªç²‰ä¸")
        return followers[:max_count]
    
    def crawl_network(self, start_uid: str, max_users: int = 500,
                     max_depth: int = 2, delay: float = 3.0) -> dict:
        """
        BFSçˆ¬å–ç¤¾äº¤ç½‘ç»œ
        
        Args:
            start_uid: èµ·å§‹ç”¨æˆ·ID
            max_users: æœ€å¤§ç”¨æˆ·æ•°
            max_depth: æœ€å¤§æ·±åº¦
            delay: è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
        """
        users = {}
        edges = []
        visited = set()
        queue = [(start_uid, 0)]
        
        pbar = tqdm(total=max_users, desc="çˆ¬å–å¾®åšç”¨æˆ·")
        
        while queue and len(users) < max_users:
            uid, depth = queue.pop(0)
            
            if uid in visited or depth > max_depth:
                continue
            
            visited.add(uid)
            
            # è·å–ç”¨æˆ·ä¿¡æ¯
            user_info = self.get_user_info(uid)
            if not user_info:
                logger.warning(f"è·³è¿‡ç”¨æˆ· {uid}")
                continue
            
            users[uid] = user_info
            pbar.update(1)
            
            time.sleep(delay)
            
            # è·å–å…³æ³¨åˆ—è¡¨æˆ–ç²‰ä¸åˆ—è¡¨
            if depth < max_depth:
                # ä¼˜å…ˆå°è¯•è·å–å…³æ³¨åˆ—è¡¨
                followings = self.get_followings(uid, max_count=20)
                
                # å¦‚æœå…³æ³¨ä¸º0ï¼Œåˆ™è·å–ç²‰ä¸åˆ—è¡¨
                if len(followings) == 0:
                    logger.info(f"  ç”¨æˆ·{uid}å…³æ³¨æ•°ä¸º0ï¼Œæ”¹ä¸ºè·å–ç²‰ä¸åˆ—è¡¨")
                    followings = self.get_followers(uid, max_count=20)
                
                for following_uid in followings:
                    edges.append((uid, following_uid))
                    
                    if following_uid not in visited and len(users) < max_users:
                        queue.append((following_uid, depth + 1))
                
                time.sleep(delay)
        
        pbar.close()
        
        return {
            'users': users,
            'edges': edges,
            'metadata': {
                'start_uid': start_uid,
                'max_depth': max_depth,
                'total_users': len(users),
                'total_edges': len(edges)
            }
        }
    
    def save_data(self, data: dict, output_path: Path):
        """ä¿å­˜æ•°æ®"""
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°: {output_path}")


def main():
    """ä¸»å‡½æ•°"""
    print("="*70)
    print("å¾®åšç¤¾äº¤ç½‘ç»œçˆ¬è™« - æœ€ç»ˆç‰ˆ")
    print("="*70)
    
    # ä½ çš„cookies
    cookies = "SINAGLOBAL=6740185828856.008.1764257392979; XSRF-TOKEN=Myn4TmTnG35cSjgyYPIJfvmV; SCF=AjiMSHwPp3pk5eVrMx10d6WYKiUi8q5VEC2hifoXmNfxm-mQDE2IPwP4DaI7i_6W3iyQ4sat5D1N02_MdRCywNM.; SUB=_2A25EStb9DeRhGeBP41cR8y3NyDuIHXVnJlY1rDV8PUNbmtANLUbakW9NRTnmMHLzxa3KXAOJoUwYFxbbtUflUmvP; SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9WFUHoUkz0PekjTvoM.HlSOx5JpX5KzhUgL.Foqp1h-7e0epe0M2dJLoIEXLxKBLBo.L12eLxK.LB.-L1K.LxKnL12eLBoqLxKML1K-LB-2LxK.L1K-LB.qt; ALF=02_1769354157; _s_tentry=weibo.com; Apache=7516984194176.165.1766762537792; ULV=1766762537794:2:1:1:7516984194176.165.1766762537792:1764257392981; WBPSESS=2JbmQMfDBf9GhITJyWUUWznL60fHFOFR2V0qqV--Q6QQ6CjSe-HiZ0xa9TFn-LDSQqDlY1BaeyAkFOeWqX_zXuy2IQtbUl_bkq6V5XSWjW4mXeVHy0BlQrpgbFODloUw3x_fxkG6hoMnOUUDzYCjtA=="
    
    start_uid = "2803301701"  # äººæ°‘æ—¥æŠ¥ - æœ‰å¾ˆå¤šç²‰ä¸
    
    print(f"\nå¼€å§‹çˆ¬å–...")
    print(f"èµ·å§‹ç”¨æˆ·: {start_uid}")
    print(f"ç›®æ ‡æ•°é‡: 500ä¸ªç”¨æˆ·")
    print(f"è¯·æ±‚é—´éš”: 3ç§’")
    print(f"\nâš ï¸  æç¤º: çˆ¬å–è¿‡ç¨‹è¾ƒæ…¢æ˜¯æ­£å¸¸çš„ï¼Œé¿å…è¢«å°IP\n")
    
    crawler = RobustWeiboCrawler(cookies)
    
    # å…ˆæµ‹è¯•å•ä¸ªç”¨æˆ·
    print("="*70)
    print("æµ‹è¯•: è·å–èµ·å§‹ç”¨æˆ·ä¿¡æ¯")
    print("="*70)
    user_info = crawler.get_user_info(start_uid)
    
    if user_info and user_info.get('screen_name'):
        print(f"\nâœ… æµ‹è¯•æˆåŠŸ!")
        print(f"   æ˜µç§°: {user_info['screen_name']}")
        print(f"   ç²‰ä¸: {user_info['followers_count']}")
        print(f"   å…³æ³¨: {user_info['follow_count']}")
        
        # ç»§ç»­çˆ¬å–
        print("\n" + "="*70)
        print("å¼€å§‹çˆ¬å–ç¤¾äº¤ç½‘ç»œ")
        print("="*70)
        
        data = crawler.crawl_network(
            start_uid=start_uid,
            max_users=500,
            max_depth=2,
            delay=3.0
        )
        
        # ä¿å­˜æ•°æ®
        output_path = Path(__file__).parent.parent / "data" / "raw" / "weibo_data.json"
        crawler.save_data(data, output_path)
        
        print(f"\n" + "="*70)
        print("çˆ¬å–å®Œæˆ!")
        print("="*70)
        print(f"ç”¨æˆ·æ•°: {data['metadata']['total_users']}")
        print(f"å…³ç³»æ•°: {data['metadata']['total_edges']}")
        print(f"æ•°æ®æ–‡ä»¶: {output_path}")
        
    else:
        print("\nâŒ æ— æ³•è·å–ç”¨æˆ·ä¿¡æ¯")
        print("\nå¯èƒ½çš„åŸå› :")
        print("1. Cookieå·²è¿‡æœŸï¼ˆæœ€å¯èƒ½ï¼‰")
        print("2. ç”¨æˆ·IDä¸å­˜åœ¨")
        print("3. è¯¥ç”¨æˆ·è®¾ç½®äº†éšç§ä¿æŠ¤")
        print("4. è¢«å¾®åšçš„åçˆ¬è™«ç³»ç»Ÿæ‹¦æˆª")
        
        print("\nğŸ’¡ è§£å†³æ–¹æ³•:")
        print("1. é‡æ–°ç™»å½•å¾®åšè·å–æœ€æ–°Cookie")
        print("2. å°è¯•ä½¿ç”¨ä½ è‡ªå·±çš„å¾®åšè´¦å·UID")
        print("3. ç¡®ä¿CookieåŒ…å« SUB å’Œ SUBP å­—æ®µ")


if __name__ == "__main__":
    main()

