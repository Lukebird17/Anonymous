"""
Featç‰¹å¾æ ‡ç­¾æå–å·¥å…· - ä»Facebook .featæ–‡ä»¶æå–æ•æ„Ÿå±æ€§
"""

import numpy as np
from typing import Dict, Tuple
from collections import Counter


def extract_feat_labels_from_facebook(feat_file: str, featnames_file: str, 
                                      target_category: str = None,
                                      min_coverage: float = 0.3,
                                      balance_threshold: float = 0.2) -> Tuple[Dict, Dict]:
    """
    ä»Facebook featæ–‡ä»¶ä¸­æå–ç‰¹å¾ä½œä¸ºæ ‡ç­¾
    
    Args:
        feat_file: .featæ–‡ä»¶è·¯å¾„
        featnames_file: .featnamesæ–‡ä»¶è·¯å¾„
        target_category: ç›®æ ‡ç‰¹å¾ç±»åˆ«ï¼ˆå¦‚'gender', 'education', 'work'ï¼‰
                        å¦‚æœä¸ºNoneï¼Œè‡ªåŠ¨é€‰æ‹©æœ€ä½³ç‰¹å¾
        min_coverage: æœ€å°ç‰¹å¾è¦†ç›–ç‡ï¼ˆè‡³å°‘æœ‰è¿™ä¸ªæ¯”ä¾‹çš„èŠ‚ç‚¹æœ‰è¯¥ç‰¹å¾ï¼‰
        balance_threshold: ç±»åˆ«å¹³è¡¡é˜ˆå€¼ï¼ˆæ¯”ä¾‹åœ¨[0.5-threshold, 0.5+threshold]å†…ï¼‰
    
    Returns:
        labels: {node_id: label} èŠ‚ç‚¹æ ‡ç­¾å­—å…¸
        feat_info: ç‰¹å¾ä¿¡æ¯å­—å…¸
    """
    
    # 1. åŠ è½½ç‰¹å¾å…ƒæ•°æ®
    feature_metadata = {}
    category_features = {}  # {category: [feat_ids]}
    
    with open(featnames_file, 'r') as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) < 2:
                continue
            
            feat_id = int(parts[0])
            rest = ' '.join(parts[1:])
            category_parts = rest.split(';')
            category = category_parts[0] if category_parts else 'unknown'
            
            feature_metadata[feat_id] = {
                'category': category,
                'full_name': rest
            }
            
            if category not in category_features:
                category_features[category] = []
            category_features[category].append(feat_id)
    
    print(f"\nğŸ“Š ç‰¹å¾ç±»åˆ«ç»Ÿè®¡:")
    for cat, feats in sorted(category_features.items(), key=lambda x: len(x[1]), reverse=True):
        print(f"  {cat}: {len(feats)} ä¸ªç‰¹å¾")
    
    # 2. åŠ è½½æ‰€æœ‰èŠ‚ç‚¹çš„ç‰¹å¾å‘é‡
    node_features = {}
    with open(feat_file, 'r') as f:
        for line in f:
            parts = line.strip().split()
            node_id = int(parts[0])
            features = np.array([int(x) for x in parts[1:]])
            node_features[node_id] = features
    
    n_nodes = len(node_features)
    print(f"  æ€»èŠ‚ç‚¹æ•°: {n_nodes}")
    
    # 3. å¦‚æœæŒ‡å®šäº†ç›®æ ‡ç±»åˆ«ï¼Œä½¿ç”¨è¯¥ç±»åˆ«çš„ç‰¹å¾
    if target_category and target_category in category_features:
        candidate_features = category_features[target_category]
        print(f"\nğŸ¯ ä½¿ç”¨æŒ‡å®šç±»åˆ«: {target_category} ({len(candidate_features)} ä¸ªå€™é€‰ç‰¹å¾)")
    else:
        # å¦åˆ™è€ƒè™‘æ‰€æœ‰ç‰¹å¾
        candidate_features = list(feature_metadata.keys())
        print(f"\nğŸ” è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç‰¹å¾ ({len(candidate_features)} ä¸ªå€™é€‰)")
    
    # 4. è¯„ä¼°æ¯ä¸ªç‰¹å¾çš„è´¨é‡
    feature_scores = []
    
    for feat_id in candidate_features:
        if feat_id >= len(node_features[list(node_features.keys())[0]]):
            continue
            
        # ç»Ÿè®¡è¯¥ç‰¹å¾çš„åˆ†å¸ƒ
        values = [node_features[nid][feat_id] for nid in node_features]
        counter = Counter(values)
        
        # è®¡ç®—è¦†ç›–ç‡ï¼ˆæœ‰è¯¥ç‰¹å¾çš„èŠ‚ç‚¹æ¯”ä¾‹ï¼‰
        num_with_feature = counter.get(1, 0)
        coverage = num_with_feature / n_nodes
        
        # å¦‚æœè¦†ç›–ç‡å¤ªä½æˆ–å¤ªé«˜ï¼Œè·³è¿‡
        if coverage < min_coverage or coverage > (1 - min_coverage):
            continue
        
        # è®¡ç®—ç±»åˆ«å¹³è¡¡æ€§ï¼ˆè¶Šæ¥è¿‘0.5è¶Šå¥½ï¼‰
        balance = abs(coverage - 0.5)
        
        # å¦‚æœç±»åˆ«ä¸¥é‡ä¸å¹³è¡¡ï¼Œè·³è¿‡
        if balance > balance_threshold:
            continue
        
        # ç»¼åˆè¯„åˆ†ï¼ˆè¦†ç›–ç‡é«˜ + å¹³è¡¡æ€§å¥½ï¼‰
        score = (1 - balance) * coverage
        
        feature_scores.append({
            'feat_id': feat_id,
            'category': feature_metadata[feat_id]['category'],
            'full_name': feature_metadata[feat_id]['full_name'],
            'coverage': coverage,
            'balance': balance,
            'score': score,
            'num_positive': num_with_feature,
            'num_negative': counter.get(0, 0)
        })
    
    # 5. é€‰æ‹©æœ€ä½³ç‰¹å¾
    if not feature_scores:
        print("âš ï¸  æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„ç‰¹å¾")
        print(f"  æç¤º: å°è¯•é™ä½min_coverage({min_coverage})æˆ–å¢å¤§balance_threshold({balance_threshold})")
        return {}, {}
    
    # æŒ‰è¯„åˆ†æ’åº
    feature_scores.sort(key=lambda x: x['score'], reverse=True)
    best_feature = feature_scores[0]
    
    # 6. æå–æ ‡ç­¾
    labels = {}
    for node_id, features in node_features.items():
        label_value = features[best_feature['feat_id']]
        if label_value in [0, 1]:  # åªä¿ç•™æœ‰æ•ˆæ ‡ç­¾
            labels[node_id] = label_value
    
    # 7. è¿”å›ä¿¡æ¯
    feat_info = {
        'feat_id': best_feature['feat_id'],
        'category': best_feature['category'],
        'full_name': best_feature['full_name'],
        'coverage': best_feature['coverage'],
        'balance': best_feature['balance'],
        'num_classes': 2,
        'class_distribution': {
            0: best_feature['num_negative'],
            1: best_feature['num_positive']
        },
        'all_candidates': feature_scores[:10]  # ä¿ç•™å‰10ä¸ªå€™é€‰ç‰¹å¾
    }
    
    print(f"\nâœ… é€‰æ‹©çš„featç‰¹å¾:")
    print(f"  ç‰¹å¾ID: {feat_info['feat_id']}")
    print(f"  ç±»åˆ«: {feat_info['category']}")
    print(f"  åç§°: {feat_info['full_name']}")
    print(f"  è¦†ç›–ç‡: {feat_info['coverage']:.2%} ({best_feature['num_positive'] + best_feature['num_negative']}/{n_nodes} èŠ‚ç‚¹)")
    print(f"  ç±»åˆ«åˆ†å¸ƒ: è´Ÿç±»={best_feature['num_negative']}, æ­£ç±»={best_feature['num_positive']}")
    print(f"  å¹³è¡¡æ€§: {(1-best_feature['balance'])*100:.1f}% (è¶Šæ¥è¿‘100%è¶Šå¥½)")
    
    if len(feature_scores) > 1:
        print(f"\nğŸ“‹ å…¶ä»–å€™é€‰ç‰¹å¾ (å‰5ä¸ª):")
        for i, fs in enumerate(feature_scores[1:6], 1):
            print(f"  {i}. [{fs['category']}] è¦†ç›–ç‡={fs['coverage']:.2%}, å¹³è¡¡æ€§={(1-fs['balance'])*100:.1f}%")
    
    return labels, feat_info


def test_feat_extraction():
    """æµ‹è¯•featç‰¹å¾æå–"""
    import os
    
    ego_id = '0'
    base_path = 'data/datasets/facebook'
    
    feat_file = os.path.join(base_path, f'{ego_id}.feat')
    featnames_file = os.path.join(base_path, f'{ego_id}.featnames')
    
    if not os.path.exists(feat_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {feat_file}")
        return
    
    print("="*70)
    print(f"æµ‹è¯• Ego {ego_id} çš„Featç‰¹å¾æå–")
    print("="*70)
    
    # æµ‹è¯•1: è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç‰¹å¾
    print("\nã€æµ‹è¯•1ã€‘è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç‰¹å¾")
    print("-"*70)
    labels_auto, info_auto = extract_feat_labels_from_facebook(
        feat_file, featnames_file
    )
    print(f"\nç»“æœ: æå–åˆ° {len(labels_auto)} ä¸ªèŠ‚ç‚¹çš„æ ‡ç­¾")
    
    # æµ‹è¯•2: æŒ‡å®šç±»åˆ«
    for category in ['gender', 'education', 'work', 'hometown']:
        print(f"\nã€æµ‹è¯•2ã€‘æŒ‡å®šç±»åˆ«: {category}")
        print("-"*70)
        labels_cat, info_cat = extract_feat_labels_from_facebook(
            feat_file, featnames_file, target_category=category
        )
        if labels_cat:
            print(f"ç»“æœ: æå–åˆ° {len(labels_cat)} ä¸ªèŠ‚ç‚¹çš„æ ‡ç­¾")
        else:
            print(f"ç»“æœ: è¯¥ç±»åˆ«æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„ç‰¹å¾")
    
    print("\n" + "="*70)
    print("æµ‹è¯•å®Œæˆï¼")
    print("="*70)


if __name__ == "__main__":
    test_feat_extraction()

