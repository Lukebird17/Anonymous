"""
è‡ªåŠ¨åŒ–Unifiedå®éªŒç»“æœå¯è§†åŒ–è„šæœ¬
ä» results/unified/ ç›®å½•è¯»å–JSONç»“æœå¹¶ç”Ÿæˆå›¾è¡¨
æ”¯æŒæ‰€æœ‰æ•°æ®é›†ï¼ˆCora, Facebookç­‰ï¼‰
"""

import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import numpy as np
import json
from pathlib import Path
from datetime import datetime

# è®¾ç½®å­—ä½“
plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# è®¾ç½®é£æ ¼
plt.style.use('default')
plt.rcParams['axes.grid'] = True
plt.rcParams['grid.alpha'] = 0.3
COLORS = {
    'primary': '#2E86AB',
    'secondary': '#A23B72', 
    'success': '#06A77D',
    'warning': '#F18F01',
    'danger': '#C73E1D',
}


class UnifiedAutoVisualizer:
    """Unifiedå®éªŒç»“æœè‡ªåŠ¨å¯è§†åŒ–å™¨"""
    
    def __init__(self, results_file=None):
        if results_file is None:
            results_file = self._find_latest_results()
        
        self.results_file = Path(results_file)
        self.output_dir = Path('results/figures')
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½ç»“æœ
        with open(self.results_file, 'r') as f:
            self.results = json.load(f)
        
        # æå–æ•°æ®é›†åç§°
        self.dataset_name = self.results.get('dataset', 'unknown')
        self.ego_id = self.results.get('ego_id', None)
        
        print(f"âœ“ åŠ è½½ç»“æœæ–‡ä»¶: {self.results_file}")
        print(f"âœ“ æ•°æ®é›†: {self.dataset_name}")
        if self.ego_id:
            print(f"âœ“ Ego ID: {self.ego_id}")
    
    def _find_latest_results(self):
        """æŸ¥æ‰¾æœ€æ–°çš„unifiedç»“æœæ–‡ä»¶"""
        results_dir = Path('results/unified')
        json_files = list(results_dir.glob('*.json'))
        
        if not json_files:
            raise FileNotFoundError("æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶ï¼è¯·å…ˆè¿è¡Œ main_experiment_unified.py")
        
        latest_file = max(json_files, key=lambda p: p.stat().st_mtime)
        return str(latest_file)
    
    def generate_all_figures(self):
        """ç”Ÿæˆæ‰€æœ‰å›¾è¡¨"""
        print("\n" + "="*70)
        print("ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        print("="*70)
        
        # 1. å»åŒ¿ååŒ–æ”»å‡»
        if 'deanonymization' in self.results and self.results['deanonymization']:
            print("\n[å›¾è¡¨ 1] å»åŒ¿ååŒ–æ”»å‡»æ€§èƒ½")
            self.plot_deanonymization()
        
        # 2. å±æ€§æ¨æ–­æ”»å‡»
        if 'attribute_inference' in self.results and self.results['attribute_inference']:
            print("\n[å›¾è¡¨ 2] å±æ€§æ¨æ–­æ”»å‡»æ€§èƒ½")
            self.plot_attribute_inference()
        
        # 3. é²æ£’æ€§æµ‹è¯•
        if 'robustness' in self.results and self.results['robustness']:
            print("\n[å›¾è¡¨ 3] é²æ£’æ€§æµ‹è¯•æ›²çº¿")
            self.plot_robustness()
        
        # 4. å·®åˆ†éšç§é˜²å¾¡
        if 'defense' in self.results and self.results['defense']:
            print("\n[å›¾è¡¨ 4] å·®åˆ†éšç§é˜²å¾¡æ•ˆæœ")
            self.plot_defense()
        
        # 5. ç»¼åˆå¯¹æ¯”
        print("\n[å›¾è¡¨ 5] ç»¼åˆå®éªŒåˆ†æ")
        self.plot_comprehensive()
        
        print("\n" + "="*70)
        print(f"âœ… æ‰€æœ‰å›¾è¡¨å·²ç”Ÿæˆï¼ä¿å­˜ä½ç½®: {self.output_dir}")
        print("="*70)
        
        # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        self.generate_text_report()
    
    def plot_deanonymization(self):
        """ç»˜åˆ¶å»åŒ¿ååŒ–æ”»å‡»ç»“æœ"""
        data = self.results['deanonymization']
        
        # æŒ‰levelå’Œmethodç»„ç»‡æ•°æ®
        levels = ['æ¸©å’Œ', 'ä¸­ç­‰', 'è¾ƒå¼º']
        methods = []
        for item in data:
            if item['method'] not in methods:
                methods.append(item['method'])
        
        # æ˜¾ç¤ºæ‰€æœ‰æ–¹æ³•ï¼ˆåŒ…æ‹¬DeepWalkï¼‰
        main_methods = methods
        
        fig, axes = plt.subplots(1, 3, figsize=(18, 5))
        
        # å‡†å¤‡æ•°æ®
        data_dict = {}
        for item in data:
            key = f"{item['level']}-{item['method']}"
            data_dict[key] = item
        
        # å®šä¹‰æ–¹æ³•é¢œè‰²
        method_colors = {
            'Baseline-Greedy': COLORS['primary'],
            'Hungarian': COLORS['secondary'],
            'Node-Features': COLORS['success'],
            'DeepWalk': COLORS['danger']
        }
        
        # å­å›¾1: Top-1å‡†ç¡®ç‡å¯¹æ¯”
        ax1 = axes[0]
        x = np.arange(len(levels))
        width = 0.8 / len(main_methods)  # åŠ¨æ€è°ƒæ•´å®½åº¦
        
        for i, method in enumerate(main_methods):
            accuracies = [data_dict[f'{level}-{method}']['accuracy'] * 100 
                         for level in levels if f'{level}-{method}' in data_dict]
            if accuracies:
                color = method_colors.get(method, list(COLORS.values())[i % len(COLORS)])
                ax1.bar(x + i*width - 0.4 + width/2, accuracies, width, label=method, color=color)
        
        ax1.set_xlabel('Anonymization Strength', fontsize=12, fontweight='bold')
        ax1.set_ylabel('Top-1 Accuracy (%)', fontsize=12, fontweight='bold')
        ax1.set_title('De-anonymization Attack - Top-1 Accuracy', fontsize=14, fontweight='bold')
        ax1.set_xticks(x)
        ax1.set_xticklabels(['Mild', 'Medium', 'Strong'])
        ax1.legend(fontsize=9)
        ax1.grid(axis='y', alpha=0.3)
        
        # å­å›¾2: Precision@5å¯¹æ¯”
        ax2 = axes[1]
        for i, method in enumerate(main_methods):
            p5_scores = [data_dict[f'{level}-{method}']['precision@5'] * 100 
                        for level in levels if f'{level}-{method}' in data_dict]
            if p5_scores:
                color = method_colors.get(method, list(COLORS.values())[i % len(COLORS)])
                ax2.plot(['Mild', 'Medium', 'Strong'], p5_scores, 'o-', linewidth=2, markersize=8,
                        label=method, color=color)
        
        ax2.set_xlabel('Anonymization Strength', fontsize=12, fontweight='bold')
        ax2.set_ylabel('Precision@5 (%)', fontsize=12, fontweight='bold')
        ax2.set_title('De-anonymization Attack - Precision@5', fontsize=14, fontweight='bold')
        ax2.legend(fontsize=9)
        ax2.grid(alpha=0.3)
        
        # å­å›¾3: MRRå¯¹æ¯”
        ax3 = axes[2]
        for i, method in enumerate(main_methods):
            mrr_scores = [data_dict[f'{level}-{method}']['mrr'] 
                         for level in levels if f'{level}-{method}' in data_dict]
            if mrr_scores:
                color = method_colors.get(method, list(COLORS.values())[i % len(COLORS)])
                ax3.plot(['Mild', 'Medium', 'Strong'], mrr_scores, 's-', linewidth=2, markersize=8,
                        label=method, color=color)
        
        ax3.set_xlabel('Anonymization Strength', fontsize=12, fontweight='bold')
        ax3.set_ylabel('MRR', fontsize=12, fontweight='bold')
        ax3.set_title('De-anonymization Attack - MRR', fontsize=14, fontweight='bold')
        ax3.legend()
        ax3.grid(alpha=0.3)
        
        plt.tight_layout()
        filename = f'{self.dataset_name}_deanonymization.png'
        if self.ego_id:
            filename = f'{self.dataset_name}_ego{self.ego_id}_deanonymization.png'
        output_path = self.output_dir / filename
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"  âœ“ å·²ä¿å­˜: {output_path.name}")
    
    def plot_attribute_inference(self):
        """ç»˜åˆ¶å±æ€§æ¨æ–­æ”»å‡»ç»“æœ"""
        data = self.results['attribute_inference']
        
        # æŒ‰hide_ratioå’Œmethodç»„ç»‡æ•°æ®
        hide_ratios = sorted(list(set([item['hide_ratio'] for item in data])))
        methods = list(set([item['method'] for item in data]))
        
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        
        # å‡†å¤‡æ•°æ®
        data_dict = {}
        for item in data:
            key = f"{item['hide_ratio']}-{item['method']}"
            data_dict[key] = item
        
        # å®šä¹‰æ–¹æ³•é¢œè‰²å’Œæ˜¾ç¤ºåç§°
        method_config = {
            'Neighbor-Voting': {'color': COLORS['warning'], 'label': 'Neighbor Voting'},
            'Label-Propagation': {'color': COLORS['success'], 'label': 'Label Propagation'},
            'GraphSAGE': {'color': COLORS['danger'], 'label': 'GraphSAGE (GNN)'}
        }
        
        # å­å›¾1: å‡†ç¡®ç‡å¯¹æ¯”ï¼ˆæŸ±çŠ¶å›¾ï¼‰
        ax1 = axes[0]
        x = np.arange(len(hide_ratios))
        width = 0.8 / len(methods)  # åŠ¨æ€è°ƒæ•´å®½åº¦
        
        hide_labels = [f'{int(r*100)}%' for r in hide_ratios]
        
        all_bars = []
        for i, method in enumerate(methods):
            if method in method_config:
                accuracies = [data_dict[f'{r}-{method}']['accuracy'] * 100 
                             for r in hide_ratios if f'{r}-{method}' in data_dict]
                
                if accuracies:
                    offset = (i - len(methods)/2 + 0.5) * width
                    bars = ax1.bar(x + offset, accuracies, width, 
                                  label=method_config[method]['label'],
                                  color=method_config[method]['color'], alpha=0.8)
                    all_bars.append(bars)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bars in all_bars:
            for bar in bars:
                height = bar.get_height()
                ax1.text(bar.get_x() + bar.get_width()/2., height,
                        f'{height:.1f}%', ha='center', va='bottom', fontsize=9)
        
        ax1.set_xlabel('Hidden Label Ratio', fontsize=12, fontweight='bold')
        ax1.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')
        ax1.set_title('Attribute Inference - Accuracy Comparison', fontsize=14, fontweight='bold')
        ax1.set_xticks(x)
        ax1.set_xticklabels(hide_labels)
        ax1.legend(fontsize=10)
        ax1.grid(axis='y', alpha=0.3)
        
        # å­å›¾2: å‡†ç¡®ç‡è¶‹åŠ¿ï¼ˆæŠ˜çº¿å›¾ï¼‰
        ax2 = axes[1]
        x_numeric = [int(r*100) for r in hide_ratios]
        
        # å®šä¹‰ä¸åŒçš„æ ‡è®°æ ·å¼
        markers = ['o', 's', '^', 'D', 'v']
        
        for i, method in enumerate(methods):
            if method in method_config:
                accuracies = [data_dict[f'{r}-{method}']['accuracy'] * 100 
                             for r in hide_ratios if f'{r}-{method}' in data_dict]
                
                if accuracies:
                    marker = markers[i % len(markers)]
                    ax2.plot(x_numeric, accuracies, f'{marker}-', linewidth=3, markersize=10,
                            label=method_config[method]['label'], 
                            color=method_config[method]['color'])
        
        ax2.set_xlabel('Hidden Label Ratio (%)', fontsize=12, fontweight='bold')
        ax2.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')
        ax2.set_title('Attribute Inference - Accuracy Trend', fontsize=14, fontweight='bold')
        ax2.legend(fontsize=10)
        ax2.grid(alpha=0.3)
        
        plt.tight_layout()
        filename = f'{self.dataset_name}_attribute_inference.png'
        if self.ego_id:
            filename = f'{self.dataset_name}_ego{self.ego_id}_attribute_inference.png'
        output_path = self.output_dir / filename
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"  âœ“ å·²ä¿å­˜: {output_path.name}")
    
    def plot_robustness(self):
        """ç»˜åˆ¶é²æ£’æ€§æµ‹è¯•ç»“æœ"""
        data = self.results['robustness']
        
        missing_ratios = sorted([item['missing_ratio'] for item in data])
        accuracies = [item['accuracy'] * 100 for item in sorted(data, key=lambda x: x['missing_ratio'])]
        
        completeness = [100 - r*100 for r in missing_ratios]
        
        # è®¡ç®—ç›¸å¯¹ä¸‹é™
        baseline_acc = accuracies[0]
        relative_decline = [(baseline_acc - acc) / baseline_acc * 100 if baseline_acc > 0 else 0 
                           for acc in accuracies]
        
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))
        
        # å­å›¾1: æ”»å‡»æˆåŠŸç‡æ›²çº¿
        ax1 = axes[0]
        ax1.plot(completeness, accuracies, 'o-', linewidth=3, markersize=12,
                color=COLORS['primary'], label='Attack Accuracy')
        
        ax1.set_xlabel('Graph Completeness (%)', fontsize=12, fontweight='bold')
        ax1.set_ylabel('Attack Accuracy (%)', fontsize=12, fontweight='bold')
        ax1.set_title('Robustness Test - Attack Success Rate', fontsize=14, fontweight='bold')
        ax1.legend()
        ax1.grid(alpha=0.3)
        ax1.invert_xaxis()  # ä»é«˜åˆ°ä½
        
        # å­å›¾2: ç›¸å¯¹ä¸‹é™ç‡
        ax2 = axes[1]
        colors = [COLORS['success'] if d < 25 else COLORS['warning'] if d < 50 else COLORS['danger']
                 for d in relative_decline]
        
        bars = ax2.bar(completeness, relative_decline, color=colors, alpha=0.8, edgecolor='black')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, val in zip(bars, relative_decline):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height,
                    f'{val:.1f}%', ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        # æ·»åŠ 50%ä¸‹é™çº¿
        ax2.axhline(y=50, color='black', linestyle='--', linewidth=2,
                   label='50% Decline Threshold', alpha=0.5)
        
        ax2.set_xlabel('Graph Completeness (%)', fontsize=12, fontweight='bold')
        ax2.set_ylabel('Relative Decline (%)', fontsize=12, fontweight='bold')
        ax2.set_title('Robustness Test - Relative Decline', fontsize=14, fontweight='bold')
        ax2.legend()
        ax2.grid(axis='y', alpha=0.3)
        ax2.invert_xaxis()
        
        plt.tight_layout()
        filename = f'{self.dataset_name}_robustness.png'
        if self.ego_id:
            filename = f'{self.dataset_name}_ego{self.ego_id}_robustness.png'
        output_path = self.output_dir / filename
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"  âœ“ å·²ä¿å­˜: {output_path.name}")
    
    def plot_defense(self):
        """ç»˜åˆ¶å·®åˆ†éšç§é˜²å¾¡ç»“æœ"""
        data = self.results['defense']
        
        epsilons = sorted([item['epsilon'] for item in data])
        edge_pres = [item['edge_preservation'] * 100 for item in sorted(data, key=lambda x: x['epsilon'])]
        utility_scores = [item['utility_score'] * 100 for item in sorted(data, key=lambda x: x['epsilon'])]
        degree_mae = [item['structural_loss']['degree_mae'] for item in sorted(data, key=lambda x: x['epsilon'])]
        
        fig, axes = plt.subplots(2, 2, figsize=(14, 10))
        
        # å­å›¾1: è¾¹ä¿ç•™ç‡
        ax1 = axes[0, 0]
        ax1.plot(epsilons, edge_pres, 'o-', linewidth=3, markersize=12,
                color=COLORS['success'])
        ax1.set_xlabel('Privacy Budget (epsilon)', fontsize=12, fontweight='bold')
        ax1.set_ylabel('Edge Preservation (%)', fontsize=12, fontweight='bold')
        ax1.set_title('Differential Privacy - Edge Preservation', fontsize=14, fontweight='bold')
        ax1.set_xscale('log')
        ax1.grid(alpha=0.3)
        ax1.axhline(y=90, color='gray', linestyle='--', alpha=0.5, label='90% Threshold')
        ax1.legend()
        
        # å­å›¾2: æ•ˆç”¨å¾—åˆ†
        ax2 = axes[0, 1]
        ax2.plot(epsilons, utility_scores, 's-', linewidth=3, markersize=12,
                color=COLORS['primary'])
        ax2.set_xlabel('Privacy Budget (epsilon)', fontsize=12, fontweight='bold')
        ax2.set_ylabel('Utility Score (%)', fontsize=12, fontweight='bold')
        ax2.set_title('Differential Privacy - Utility Score', fontsize=14, fontweight='bold')
        ax2.set_xscale('log')
        ax2.grid(alpha=0.3)
        ax2.axhline(y=90, color='gray', linestyle='--', alpha=0.5, label='90% Threshold')
        ax2.legend()
        
        # å­å›¾3: åº¦åˆ†å¸ƒMAE
        ax3 = axes[1, 0]
        ax3.plot(epsilons, degree_mae, '^-', linewidth=3, markersize=12,
                color=COLORS['danger'])
        ax3.set_xlabel('Privacy Budget (epsilon)', fontsize=12, fontweight='bold')
        ax3.set_ylabel('Degree Distribution MAE', fontsize=12, fontweight='bold')
        ax3.set_title('Differential Privacy - Degree Distribution Error', fontsize=14, fontweight='bold')
        ax3.set_xscale('log')
        ax3.grid(alpha=0.3)
        
        # å­å›¾4: éšç§-æ•ˆç”¨æƒè¡¡æ•£ç‚¹å›¾
        ax4 = axes[1, 1]
        scatter = ax4.scatter(utility_scores, edge_pres,
                            s=[1000/e for e in epsilons],
                            c=epsilons, cmap='viridis',
                            alpha=0.7, edgecolors='black', linewidth=2)
        
        # æ·»åŠ æ ‡ç­¾
        for i, eps in enumerate(epsilons):
            ax4.annotate(f'eps={eps}',
                       (utility_scores[i], edge_pres[i]),
                       xytext=(5, 5), textcoords='offset points',
                       fontsize=11, fontweight='bold')
        
        # æ·»åŠ å‚è€ƒçº¿
        ax4.axhline(y=90, color='gray', linestyle='--', alpha=0.5)
        ax4.axvline(x=90, color='gray', linestyle='--', alpha=0.5)
        
        # æ ‡æ³¨æ¨èå€¼ï¼ˆÎµ=1.0ï¼‰
        if 1.0 in epsilons:
            recommended_idx = epsilons.index(1.0)
            ax4.plot(utility_scores[recommended_idx], edge_pres[recommended_idx],
                    'r*', markersize=25, label='Recommended (eps=1.0)')
        
        ax4.set_xlabel('Utility Score (%)', fontsize=12, fontweight='bold')
        ax4.set_ylabel('Edge Preservation (%)', fontsize=12, fontweight='bold')
        ax4.set_title('Privacy-Utility Tradeoff', fontsize=14, fontweight='bold')
        ax4.legend()
        ax4.grid(alpha=0.3)
        
        plt.colorbar(scatter, ax=ax4, label='Îµ')
        
        plt.tight_layout()
        filename = f'{self.dataset_name}_defense.png'
        if self.ego_id:
            filename = f'{self.dataset_name}_ego{self.ego_id}_defense.png'
        output_path = self.output_dir / filename
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"  âœ“ å·²ä¿å­˜: {output_path.name}")
    
    def plot_comprehensive(self):
        """ç»˜åˆ¶ç»¼åˆå¯¹æ¯”å›¾"""
        fig = plt.figure(figsize=(16, 10))
        gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3)
        
        # å­å›¾1: æ‰€æœ‰æ”»å‡»æ–¹æ³•å¯¹æ¯”
        ax1 = fig.add_subplot(gs[0, :])
        
        methods_all = []
        accuracies_all = []
        colors_all = []
        
        # å»åŒ¿ååŒ–ï¼ˆæ¸©å’ŒåŒ¿ååŒ–ä¸‹çš„æœ€ä½³ç»“æœï¼‰
        if 'deanonymization' in self.results:
            mild_data = [item for item in self.results['deanonymization'] 
                        if item['level'] == 'æ¸©å’Œ' and item['method'] != 'DeepWalk']
            for item in mild_data:
                methods_all.append(f"Identity-{item['method']}")
                accuracies_all.append(item['accuracy'] * 100)
                colors_all.append(COLORS['primary'])
        
        # å±æ€§æ¨æ–­ï¼ˆ30%éšè—ï¼‰
        if 'attribute_inference' in self.results:
            attr_30 = [item for item in self.results['attribute_inference'] 
                      if item['hide_ratio'] == 0.3]
            for item in attr_30:
                methods_all.append(f"Attribute-{item['method']}")
                accuracies_all.append(item['accuracy'] * 100)
                colors_all.append(COLORS['secondary'])
        
        bars = ax1.barh(methods_all, accuracies_all, color=colors_all, alpha=0.8, edgecolor='black')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, acc in zip(bars, accuracies_all):
            width = bar.get_width()
            ax1.text(width, bar.get_y() + bar.get_height()/2.,
                    f' {acc:.1f}%', ha='left', va='center', fontsize=11, fontweight='bold')
        
        ax1.set_xlabel('Accuracy (%)', fontsize=13, fontweight='bold')
        ax1.set_title('[Comprehensive] All Attack Methods Performance (Best Case)',
                     fontsize=15, fontweight='bold', pad=15)
        ax1.grid(axis='x', alpha=0.3)
        
        # å­å›¾2: å…³é”®å‘ç°æ€»ç»“
        ax2 = fig.add_subplot(gs[1, :])
        ax2.axis('off')
        
        # è®¡ç®—å…³é”®ç»Ÿè®¡æ•°æ®
        summary_lines = ["[Key Findings Summary]\n"]
        
        if 'deanonymization' in self.results:
            best_deanon = max([item for item in self.results['deanonymization'] 
                              if item['level'] == 'æ¸©å’Œ'],
                             key=lambda x: x['accuracy'])
            summary_lines.append(f"1. Identity De-anonymization:")
            summary_lines.append(f"   * Best Method: {best_deanon['method']} ({best_deanon['accuracy']*100:.2f}%)")
            summary_lines.append(f"   * Improvement: {best_deanon['improvement_factor']:.0f}x vs Random")
        
        if 'attribute_inference' in self.results:
            best_attr = max(self.results['attribute_inference'], 
                           key=lambda x: x['accuracy'])
            summary_lines.append(f"\n2. Attribute Inference:")
            summary_lines.append(f"   * Best Method: {best_attr['method']} ({best_attr['accuracy']*100:.2f}%)")
            summary_lines.append(f"   * Hidden Ratio: {best_attr['hide_ratio']*100:.0f}%")
        
        if 'robustness' in self.results:
            rob_data = sorted(self.results['robustness'], key=lambda x: x['missing_ratio'])
            baseline = rob_data[0]['accuracy'] * 100
            missing_ratios_str = ', '.join([f'{int(x["missing_ratio"]*100)}%' for x in rob_data])
            summary_lines.append(f"\n3. Robustness Test:")
            summary_lines.append(f"   * Baseline Accuracy: {baseline:.2f}%")
            summary_lines.append(f"   * Test Missing Ratios: {missing_ratios_str}")
        
        if 'defense' in self.results:
            summary_lines.append(f"\n4. Differential Privacy:")
            summary_lines.append(f"   * Recommended epsilon: 1.0")
            eps1_data = [item for item in self.results['defense'] if item['epsilon'] == 1.0]
            if eps1_data:
                summary_lines.append(f"   * Edge Preservation: {eps1_data[0]['edge_preservation']*100:.2f}%")
                summary_lines.append(f"   * Utility Score: {eps1_data[0]['utility_score']*100:.2f}%")
        
        summary_lines.append(f"\n[Summary]")
        summary_lines.append(f"Dataset {self.dataset_name} shows significant")
        summary_lines.append(f"privacy leakage risks under multi-dimensional")
        summary_lines.append(f"attacks. DP defense effectively mitigates risks!")
        
        summary_text = "\n".join(summary_lines)
        
        ax2.text(0.05, 0.95, summary_text,
                transform=ax2.transAxes,
                fontsize=11,
                verticalalignment='top',
                fontfamily='monospace',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))
        
        plt.tight_layout()
        filename = f'{self.dataset_name}_comprehensive.png'
        if self.ego_id:
            filename = f'{self.dataset_name}_ego{self.ego_id}_comprehensive.png'
        output_path = self.output_dir / filename
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        plt.close()
        print(f"  âœ“ å·²ä¿å­˜: {output_path.name}")
    
    def generate_text_report(self):
        """ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š"""
        report_lines = []
        report_lines.append("="*70)
        report_lines.append("å®éªŒç»“æœæ€»ç»“æŠ¥å‘Š")
        report_lines.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append(f"æ•°æ®é›†: {self.dataset_name}")
        if self.ego_id:
            report_lines.append(f"Ego ID: {self.ego_id}")
        report_lines.append(f"ç»“æœæ–‡ä»¶: {self.results_file}")
        report_lines.append("="*70)
        
        # å›¾ç»Ÿè®¡
        if 'graph_stats' in self.results:
            stats = self.results['graph_stats']
            report_lines.append("\nã€å›¾ç»Ÿè®¡ä¿¡æ¯ã€‘")
            report_lines.append(f"  èŠ‚ç‚¹æ•°: {stats['nodes']}")
            report_lines.append(f"  è¾¹æ•°: {stats['edges']}")
            report_lines.append(f"  å¹³å‡åº¦: {stats['avg_degree']:.2f}")
            report_lines.append(f"  å¯†åº¦: {stats['density']:.6f}")
        
        # å»åŒ¿ååŒ–
        if 'deanonymization' in self.results:
            report_lines.append("\nã€å»åŒ¿ååŒ–æ”»å‡»ã€‘")
            for item in self.results['deanonymization']:
                report_lines.append(f"\n{item['level']} - {item['method']}:")
                report_lines.append(f"  Top-1å‡†ç¡®ç‡: {item['accuracy']*100:.2f}%")
                report_lines.append(f"  Precision@5: {item['precision@5']*100:.2f}%")
                report_lines.append(f"  MRR: {item['mrr']:.4f}")
                report_lines.append(f"  æå‡å€æ•°: {item['improvement_factor']:.0f}x")
        
        # å±æ€§æ¨æ–­
        if 'attribute_inference' in self.results:
            report_lines.append("\nã€å±æ€§æ¨æ–­æ”»å‡»ã€‘")
            for item in self.results['attribute_inference']:
                report_lines.append(f"\néšè—{item['hide_ratio']*100:.0f}% - {item['method']}:")
                report_lines.append(f"  å‡†ç¡®ç‡: {item['accuracy']*100:.2f}%")
                report_lines.append(f"  æ­£ç¡®: {item['correct']}/{item['total']}")
        
        # é²æ£’æ€§
        if 'robustness' in self.results:
            report_lines.append("\nã€é²æ£’æ€§æµ‹è¯•ã€‘")
            for item in self.results['robustness']:
                report_lines.append(f"ç¼ºå¤±{item['missing_ratio']*100:.0f}%: å‡†ç¡®ç‡ {item['accuracy']*100:.2f}%")
        
        # é˜²å¾¡
        if 'defense' in self.results:
            report_lines.append("\nã€å·®åˆ†éšç§é˜²å¾¡ã€‘")
            for item in self.results['defense']:
                report_lines.append(f"\nÎµ = {item['epsilon']}:")
                report_lines.append(f"  è¾¹ä¿ç•™ç‡: {item['edge_preservation']*100:.2f}%")
                report_lines.append(f"  æ•ˆç”¨å¾—åˆ†: {item['utility_score']*100:.2f}%")
                report_lines.append(f"  åº¦åˆ†å¸ƒMAE: {item['structural_loss']['degree_mae']:.2f}")
        
        report_lines.append("\n" + "="*70)
        
        # ä¿å­˜æŠ¥å‘Š
        report_text = "\n".join(report_lines)
        filename = f'{self.dataset_name}_report.txt'
        if self.ego_id:
            filename = f'{self.dataset_name}_ego{self.ego_id}_report.txt'
        output_path = self.output_dir / filename
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        print(f"\nâœ“ å·²ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š: {output_path.name}")
        print("\n" + report_text)


def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*70)
    print("Unifiedå®éªŒç»“æœè‡ªåŠ¨å¯è§†åŒ–")
    print("="*70)
    
    try:
        visualizer = UnifiedAutoVisualizer()
        visualizer.generate_all_figures()
        
        print("\nâœ… æ‰€æœ‰å¯è§†åŒ–ä»»åŠ¡å®Œæˆï¼")
        print(f"\nğŸ“Š å›¾è¡¨ä½ç½®: {visualizer.output_dir}")
        print("\nç”Ÿæˆçš„å›¾è¡¨:")
        for fig_file in sorted(visualizer.output_dir.glob(f'{visualizer.dataset_name}*.png')):
            print(f"  - {fig_file.name}")
        
        return 0
    except Exception as e:
        print(f"\nâŒ å¯è§†åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    import sys
    sys.exit(main())

