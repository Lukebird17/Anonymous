"""
ç»Ÿä¸€å®éªŒè„šæœ¬ - æ•´åˆæ‰€æœ‰å®éªŒåŠŸèƒ½
æ”¯æŒæ‰€æœ‰æ•°æ®é›†å’Œæ‰€æœ‰å®éªŒæ¨¡å¼

ä½¿ç”¨ç¤ºä¾‹:
  # Facebook Combined - å®Œæ•´å®éªŒ
  python main_experiment_unified.py --dataset facebook --mode all
  
  # Facebook Ego - ä¼˜åŒ–æ”»å‡»
  python main_experiment_unified.py --dataset facebook_ego --ego_id 0 --mode attack
  
  # Cora - å±æ€§æ¨æ–­
  python main_experiment_unified.py --dataset cora --mode attribute_inference
  
  # å¿«é€Ÿæµ‹è¯•
  python main_experiment_unified.py --dataset facebook_ego --ego_id 698 --mode quick
"""

import argparse
import os
import sys
import numpy as np
import networkx as nx
from datetime import datetime
from collections import defaultdict, Counter
import json

# å¯¼å…¥æ‰€æœ‰å¿…è¦çš„æ¨¡å—
from data.dataset_loader import DatasetLoader
from attack.embedding_match import EmbeddingMatcher
from attack.baseline_match import BaselineMatcher
from attack.attribute_inference import AttributeInferenceAttack, LabelPropagationAttack
from attack.neighborhood_sampler import NeighborhoodSampler, RobustnessSimulator
from defense.differential_privacy import DifferentialPrivacyDefense, PrivacyUtilityEvaluator
from utils.comprehensive_metrics import (
    DeAnonymizationMetrics,
    AttributeInferenceMetrics,
    RobustnessMetrics,
    PrivacyMetrics,
    ComprehensiveEvaluator
)
from preprocessing.anonymizer import GraphAnonymizer
from models.deepwalk import DeepWalkModel
from models.feature_extractor import FeatureExtractor


class UnifiedExperiment:
    """ç»Ÿä¸€å®éªŒæ¡†æ¶"""
    
    def __init__(self, dataset_name, ego_id=None, output_dir="results/unified"):
        """
        åˆå§‹åŒ–ç»Ÿä¸€å®éªŒ
        
        Args:
            dataset_name: æ•°æ®é›†åç§°
            ego_id: egoç½‘ç»œID (ä»…ç”¨äºfacebook_ego)
            output_dir: è¾“å‡ºç›®å½•
        """
        self.dataset_name = dataset_name
        self.ego_id = ego_id
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # åŠ è½½æ•°æ®
        self.G, self.attributes = self._load_dataset()
        
        # ç»“æœå­˜å‚¨
        self.results = {
            'dataset': dataset_name,
            'ego_id': ego_id,
            'timestamp': datetime.now().isoformat(),
            'graph_stats': self._get_graph_stats()
        }
    
    def _load_dataset(self):
        """åŠ è½½æ•°æ®é›†"""
        loader = DatasetLoader()
        
        if self.dataset_name == 'facebook':
            return loader._load_facebook_combined()
        elif self.dataset_name == 'facebook_ego':
            ego_id = self.ego_id or '0'
            return loader.load_facebook(ego_network=ego_id)
        elif self.dataset_name == 'cora':
            return loader.load_cora()
        elif self.dataset_name == 'citeseer':
            return loader.load_citeseer()
        elif self.dataset_name == 'weibo':
            return loader.load_weibo()
        else:
            raise ValueError(f"æœªçŸ¥æ•°æ®é›†: {self.dataset_name}")
    
    def _get_graph_stats(self):
        """è·å–å›¾ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'nodes': self.G.number_of_nodes(),
            'edges': self.G.number_of_edges(),
            'avg_degree': 2 * self.G.number_of_edges() / self.G.number_of_nodes() if self.G.number_of_nodes() > 0 else 0,
            'density': nx.density(self.G),
        }
        
        if self.attributes:
            stats['nodes_with_attributes'] = len(self.attributes)
            # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡ç­¾
            has_labels = any('label' in attr for attr in self.attributes.values() if isinstance(attr, dict))
            has_circles = any('circles' in attr for attr in self.attributes.values() if isinstance(attr, dict))
            has_features = any('features' in attr for attr in self.attributes.values() if isinstance(attr, dict))
            
            stats['has_labels'] = has_labels
            stats['has_circles'] = has_circles
            stats['has_features'] = has_features
        
        return stats
    
    def print_dataset_info(self):
        """æ‰“å°æ•°æ®é›†ä¿¡æ¯"""
        print(f"\n{'='*70}")
        print(f"ç»Ÿä¸€å®éªŒæ¡†æ¶")
        print(f"æ•°æ®é›†: {self.dataset_name}")
        if self.ego_id:
            print(f"Egoç½‘ç»œID: {self.ego_id}")
        print(f"{'='*70}")
        
        print(f"\næ•°æ®é›†ä¿¡æ¯:")
        print(f"  - èŠ‚ç‚¹æ•°: {self.results['graph_stats']['nodes']}")
        print(f"  - è¾¹æ•°: {self.results['graph_stats']['edges']}")
        print(f"  - å¹³å‡åº¦: {self.results['graph_stats']['avg_degree']:.2f}")
        print(f"  - å¯†åº¦: {self.results['graph_stats']['density']:.4f}")
        
        if self.attributes:
            print(f"  - æœ‰å±æ€§çš„èŠ‚ç‚¹æ•°: {self.results['graph_stats']['nodes_with_attributes']}")
            if self.results['graph_stats'].get('has_labels'):
                print(f"  - âœ… åŒ…å«èŠ‚ç‚¹æ ‡ç­¾")
            if self.results['graph_stats'].get('has_circles'):
                print(f"  - âœ… åŒ…å«ç¤¾äº¤åœˆæ ‡ç­¾")
            if self.results['graph_stats'].get('has_features'):
                print(f"  - âœ… åŒ…å«èŠ‚ç‚¹ç‰¹å¾å‘é‡")
    
    def run_deanonymization_attack(self, anonymization_levels=None):
        """
        è¿è¡Œå»åŒ¿ååŒ–æ”»å‡»å®éªŒ
        
        Args:
            anonymization_levels: åŒ¿ååŒ–å¼ºåº¦åˆ—è¡¨
        """
        print(f"\n{'='*70}")
        print("ã€é˜¶æ®µ1ã€‘èº«ä»½å»åŒ¿ååŒ–æ”»å‡»")
        print(f"{'='*70}")
        
        if anonymization_levels is None:
            anonymization_levels = [
                (0.95, 0.02, "æ¸©å’Œ"),
                (0.90, 0.05, "ä¸­ç­‰"),
                (0.85, 0.10, "è¾ƒå¼º"),
            ]
        
        results = []
        
        for edge_retention, noise_ratio, level_name in anonymization_levels:
            print(f"\n{'='*60}")
            print(f"åŒ¿ååŒ–å¼ºåº¦: {level_name} (ä¿ç•™{edge_retention:.0%}è¾¹, æ·»åŠ {noise_ratio:.0%}å™ªå£°)")
            print(f"{'='*60}")
            
            # åŒ¿ååŒ–
            anonymizer = GraphAnonymizer(self.G)
            G_anon, node_mapping = anonymizer.anonymize_with_perturbation(
                edge_retention_ratio=edge_retention,
                noise_edge_ratio=noise_ratio
            )
            
            ground_truth = {orig: node_mapping[orig] for orig in self.G.nodes() if orig in node_mapping}
            print(f"åŒ¿åå›¾: {G_anon.number_of_nodes()} èŠ‚ç‚¹, {G_anon.number_of_edges()} è¾¹")
            
            # æ–¹æ³•1: Baselineè´ªå¿ƒåŒ¹é…
            print(f"\nã€æ–¹æ³•1ã€‘Baselineè´ªå¿ƒåŒ¹é…")
            try:
                baseline = BaselineMatcher(self.G, G_anon, similarity_metric='cosine')
                predictions = baseline.match_by_features(top_k=20)
                metrics = DeAnonymizationMetrics.calculate_all_metrics(predictions, ground_truth)
                
                print(f"  - Top-1å‡†ç¡®ç‡: {metrics['accuracy']:.2%}")
                print(f"  - Precision@5: {metrics['precision@5']:.2%}")
                print(f"  - Precision@10: {metrics['precision@10']:.2%}")
                print(f"  - MRR: {metrics['mrr']:.4f}")
                
                results.append({
                    'level': level_name,
                    'method': 'Greedy',
                    **metrics
                })
            except Exception as e:
                print(f"  å¤±è´¥: {e}")
            
            # æ–¹æ³•2: åŒˆç‰™åˆ©ç®—æ³•
            print(f"\nã€æ–¹æ³•2ã€‘åŒˆç‰™åˆ©ç®—æ³•ï¼ˆæœ€ä¼˜åŒ¹é…ï¼‰")
            try:
                from scipy.optimize import linear_sum_assignment
                from sklearn.preprocessing import StandardScaler
                from sklearn.metrics.pairwise import cosine_similarity
                from models.feature_extractor import FeatureExtractor
                
                extractor = FeatureExtractor()
                nodes_orig = sorted(list(self.G.nodes()))
                nodes_anon = sorted(list(G_anon.nodes()))
                
                features_orig = extractor.extract_node_features(self.G, nodes_orig)
                features_anon = extractor.extract_node_features(G_anon, nodes_anon)
                
                scaler = StandardScaler()
                features_orig = scaler.fit_transform(features_orig)
                features_anon = scaler.transform(features_anon)
                
                similarity = cosine_similarity(features_orig, features_anon)
                
                predictions = {}
                for i, orig_node in enumerate(nodes_orig):
                    top_indices = np.argsort(similarity[i])[::-1][:20]
                    anon_nodes = [nodes_anon[idx] for idx in top_indices if idx < len(nodes_anon)]
                    predictions[orig_node] = anon_nodes
                
                metrics = DeAnonymizationMetrics.calculate_all_metrics(predictions, ground_truth)
                
                print(f"  - Top-1å‡†ç¡®ç‡: {metrics['accuracy']:.2%}")
                print(f"  - Precision@5: {metrics['precision@5']:.2%}")
                print(f"  - Precision@10: {metrics['precision@10']:.2%}")
                print(f"  - MRR: {metrics['mrr']:.4f}")
                
                results.append({
                    'level': level_name,
                    'method': 'Hungarian',
                    **metrics
                })
            except Exception as e:
                print(f"  å¤±è´¥: {e}")
            
            # æ–¹æ³•3: å›¾æ ¸æ–¹æ³•ï¼ˆGraph Kernelï¼‰- æ›¿ä»£è¿‡äºå‡†ç¡®çš„ç‰¹å¾åŒ¹é…
            print(f"\nã€æ–¹æ³•3ã€‘å›¾æ ¸ç›¸ä¼¼åº¦åŒ¹é…")
            try:
                from models.feature_extractor import FeatureExtractor
                
                extractor = FeatureExtractor()
                nodes_orig = sorted(list(self.G.nodes()))
                nodes_anon = sorted(list(G_anon.nodes()))
                
                # æå–æ›´å¤šç»“æ„ç‰¹å¾
                features_orig = []
                features_anon = []
                
                for node in nodes_orig:
                    # æå–å±€éƒ¨ç»“æ„ç‰¹å¾
                    neighbors = list(self.G.neighbors(node))
                    deg = self.G.degree(node)
                    clustering = nx.clustering(self.G, node)
                    
                    # 2-hopé‚»å±…æ•°é‡
                    two_hop = set()
                    for n in neighbors:
                        two_hop.update(self.G.neighbors(n))
                    two_hop_count = len(two_hop - set(neighbors) - {node})
                    
                    features_orig.append([deg, clustering, two_hop_count, len(neighbors)])
                
                for node in nodes_anon:
                    neighbors = list(G_anon.neighbors(node))
                    deg = G_anon.degree(node)
                    clustering = nx.clustering(G_anon, node)
                    
                    two_hop = set()
                    for n in neighbors:
                        two_hop.update(G_anon.neighbors(n))
                    two_hop_count = len(two_hop - set(neighbors) - {node})
                    
                    features_anon.append([deg, clustering, two_hop_count, len(neighbors)])
                
                features_orig = np.array(features_orig)
                features_anon = np.array(features_anon)
                
                # æ ‡å‡†åŒ–
                from sklearn.preprocessing import StandardScaler
                scaler = StandardScaler()
                features_orig = scaler.fit_transform(features_orig)
                features_anon = scaler.transform(features_anon)
                
                # è®¡ç®—ç›¸ä¼¼åº¦
                from sklearn.metrics.pairwise import cosine_similarity
                similarity = cosine_similarity(features_orig, features_anon)
                
                predictions = {}
                for i, orig_node in enumerate(nodes_orig):
                    top_indices = np.argsort(similarity[i])[::-1][:20]
                    anon_nodes = [nodes_anon[idx] for idx in top_indices if idx < len(nodes_anon)]
                    predictions[orig_node] = anon_nodes
                
                metrics = DeAnonymizationMetrics.calculate_all_metrics(predictions, ground_truth)
                
                print(f"  - Top-1å‡†ç¡®ç‡: {metrics['accuracy']:.2%}")
                print(f"  - Precision@5: {metrics['precision@5']:.2%}")
                print(f"  - Precision@10: {metrics['precision@10']:.2%}")
                print(f"  - MRR: {metrics['mrr']:.4f}")
                
                results.append({
                    'level': level_name,
                    'method': 'Graph-Kernel',
                    **metrics
                })
            except Exception as e:
                print(f"  å¤±è´¥: {e}")
            
            # æ–¹æ³•4: DeepWalkå›¾åµŒå…¥ï¼ˆåœ¨æ‰€æœ‰åŒ¿ååŒ–å¼ºåº¦ä¸‹æµ‹è¯•ï¼‰
            print(f"\nã€æ–¹æ³•4ã€‘DeepWalkå›¾åµŒå…¥ï¼ˆè®¾è®¡è¦æ±‚çš„æ–¹æ³•ï¼‰")
            try:
                from models.deepwalk import DeepWalkModel
                
                nodes_orig = sorted(list(self.G.nodes()))
                nodes_anon = sorted(list(G_anon.nodes()))
                
                # ä½¿ç”¨ä¼˜åŒ–çš„å‚æ•°
                deepwalk = DeepWalkModel(
                    dimensions=256,      # å¢åŠ ç»´åº¦
                    walk_length=100,     # å¢åŠ æ¸¸èµ°é•¿åº¦
                    num_walks=20,        # å¢åŠ æ¸¸èµ°æ¬¡æ•°
                    window_size=10,
                    workers=4
                )
                
                print("  è®­ç»ƒåŸå§‹å›¾åµŒå…¥...")
                emb_orig = deepwalk.train(self.G)
                print("  è®­ç»ƒåŒ¿åå›¾åµŒå…¥...")
                emb_anon = deepwalk.train(G_anon)
                
                from attack.embedding_match import EmbeddingMatcher
                embedder = EmbeddingMatcher(self.G, G_anon)
                embedder.embeddings_orig = emb_orig
                embedder.embeddings_anon = emb_anon
                
                predictions_idx = embedder.match_by_similarity(top_k=20)
                
                # è½¬æ¢ä¸ºèŠ‚ç‚¹IDæ ¼å¼
                predictions = {}
                for orig_idx, anon_indices in predictions_idx.items():
                    if orig_idx < len(nodes_orig):
                        orig_node = nodes_orig[orig_idx]
                        anon_nodes = [nodes_anon[idx] for idx in anon_indices 
                                     if idx < len(nodes_anon)]
                        predictions[orig_node] = anon_nodes
                
                metrics = DeAnonymizationMetrics.calculate_all_metrics(predictions, ground_truth)
                
                print(f"  - Top-1å‡†ç¡®ç‡: {metrics['accuracy']:.2%}")
                print(f"  - Precision@5: {metrics['precision@5']:.2%}")
                print(f"  - Precision@10: {metrics['precision@10']:.2%}")
                print(f"  - MRR: {metrics['mrr']:.4f}")
                
                results.append({
                    'level': level_name,
                    'method': 'DeepWalk',
                    **metrics
                })
            except Exception as e:
                print(f"  å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        self.results['deanonymization'] = results
        return results
    
    def run_attribute_inference(self, hide_ratios=None, test_feat=True, test_mgn=True):
        """
        è¿è¡Œå±æ€§æ¨æ–­æ”»å‡» - æ”¯æŒCircleså’ŒFeatä¸¤ç§æ¨æ–­ç›®æ ‡
        
        Args:
            hide_ratios: éšè—æ ‡ç­¾çš„æ¯”ä¾‹åˆ—è¡¨
            test_feat: æ˜¯å¦åŒæ—¶æµ‹è¯•Featç‰¹å¾æ¨æ–­
            test_mgn: æ˜¯å¦æµ‹è¯•MGN
        """
        print(f"\n{'='*70}")
        print("ã€é˜¶æ®µ2ã€‘å±æ€§æ¨æ–­æ”»å‡»")
        print(f"{'='*70}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡ç­¾
        has_labels = self.results['graph_stats'].get('has_labels')
        has_circles = self.results['graph_stats'].get('has_circles')
        has_features = self.results['graph_stats'].get('has_features')
        
        if not (has_labels or has_circles):
            print("âš ï¸  è¯¥æ•°æ®é›†æ²¡æœ‰èŠ‚ç‚¹æ ‡ç­¾ï¼Œè·³è¿‡å±æ€§æ¨æ–­å®éªŒ")
            return []
        
        if hide_ratios is None:
            hide_ratios = [0.3, 0.5, 0.7]
        
        results = []
        
        # ========== å‡†å¤‡Circlesæ ‡ç­¾æ•°æ® ==========
        circles_labels = {}
        feat_labels = {}
        feat_info = None
        
        if has_circles:
            # ä½¿ç”¨ç¤¾äº¤åœˆæ ‡ç­¾ï¼ˆåªåŒ…å«å›¾ä¸­çš„èŠ‚ç‚¹ï¼‰
            for node in self.G.nodes():
                if node in self.attributes and 'circles' in self.attributes[node]:
                    circles = self.attributes[node]['circles']
                    if circles:
                        circles_labels[node] = circles[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªåœˆä½œä¸ºæ ‡ç­¾
        elif has_labels:
            # ä½¿ç”¨å¸¸è§„æ ‡ç­¾ï¼ˆCoraç­‰ï¼ŒåªåŒ…å«å›¾ä¸­çš„èŠ‚ç‚¹ï¼‰
            for node in self.G.nodes():
                if node in self.attributes and 'label' in self.attributes[node]:
                    circles_labels[node] = self.attributes[node]['label']
        
        # ========== å°è¯•æå–Featæ ‡ç­¾ ==========
        if test_feat and self.dataset_name == 'facebook_ego' and has_features:
            print(f"\n{'='*70}")
            print("ğŸ”¥ æå–Featæ•æ„Ÿå±æ€§æ ‡ç­¾")
            print(f"{'='*70}")
            
            try:
                from data.feat_label_extractor import extract_feat_labels_from_facebook
                
                feat_file = f'data/datasets/facebook/{self.ego_id}.feat'
                featnames_file = f'data/datasets/facebook/{self.ego_id}.featnames'
                
                feat_labels, feat_info = extract_feat_labels_from_facebook(
                    feat_file, featnames_file,
                    target_category=None,  # è‡ªåŠ¨é€‰æ‹©æœ€ä½³ç‰¹å¾
                    min_coverage=0.3,
                    balance_threshold=0.25
                )
                
                if feat_labels:
                    # è¿‡æ»¤æ‰ä¸åœ¨å›¾ä¸­çš„èŠ‚ç‚¹
                    original_count = len(feat_labels)
                    feat_labels = {n: feat_labels[n] for n in feat_labels if n in self.G}
                    filtered_count = original_count - len(feat_labels)
                    
                    if filtered_count > 0:
                        print(f"âš ï¸  è¿‡æ»¤æ‰ {filtered_count} ä¸ªä¸åœ¨å›¾ä¸­çš„Featæ ‡ç­¾èŠ‚ç‚¹")
                    
                    if feat_labels:
                        print(f"âœ… æˆåŠŸæå–Featæ ‡ç­¾: {len(feat_labels)} ä¸ªèŠ‚ç‚¹ï¼ˆåœ¨å›¾ä¸­ï¼‰")
                    else:
                        print(f"âš ï¸  æ‰€æœ‰Featæ ‡ç­¾èŠ‚ç‚¹éƒ½ä¸åœ¨å›¾ä¸­")
                        test_feat = False
                else:
                    print(f"âš ï¸  æœªèƒ½æå–Featæ ‡ç­¾")
                    test_feat = False
            except Exception as e:
                print(f"âš ï¸  Featæå–å¤±è´¥: {e}")
                test_feat = False
        else:
            test_feat = False
        
        # ========== é€‰æ‹©é»˜è®¤æ ‡ç­¾ ==========
        node_labels = circles_labels if circles_labels else {}
        
        if not node_labels:
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ ‡ç­¾æ•°æ®")
            return []
        
        print(f"\nğŸ“Š æ ‡ç­¾ç»Ÿè®¡:")
        print(f"  Circlesæ ‡ç­¾èŠ‚ç‚¹æ•°: {len(circles_labels)}")
        if circles_labels:
            unique_circles = set(circles_labels.values())
            print(f"  Circleså”¯ä¸€æ ‡ç­¾æ•°: {len(unique_circles)}")
        
        if test_feat and feat_labels:
            print(f"  Featæ ‡ç­¾èŠ‚ç‚¹æ•°: {len(feat_labels)}")
            print(f"  Featç‰¹å¾: {feat_info['category']} - {feat_info['full_name']}")
            print(f"  Featç±»åˆ«åˆ†å¸ƒ: {feat_info['class_distribution']}")
        
        # ========== è¿è¡Œæ¨æ–­å®éªŒ ==========
        for hide_ratio in hide_ratios:
            print(f"\n{'='*60}")
            print(f"éšè— {hide_ratio:.0%} èŠ‚ç‚¹çš„æ ‡ç­¾")
            print(f"{'='*60}")
            
            # ===== æµ‹è¯•1: Circlesæ ‡ç­¾æ¨æ–­ =====
            if circles_labels:
                self._test_inference_on_labels(
                    circles_labels, hide_ratio, results, 
                    label_type="Circles", test_graphsage=True, test_mgn=test_mgn
                )
            
            # ===== æµ‹è¯•2: Featæ ‡ç­¾æ¨æ–­ =====
            if test_feat and feat_labels:
                print(f"\n{'â”€'*60}")
                print(f"ğŸ”¥ Featæ•æ„Ÿå±æ€§æ¨æ–­ ({feat_info['category']})")
                print(f"{'â”€'*60}")
                self._test_inference_on_labels(
                    feat_labels, hide_ratio, results,
                    label_type="Feat", test_graphsage=True, test_mgn=test_mgn,  # âœ… ç°åœ¨ä¹Ÿæµ‹è¯•GraphSAGE/MGN
                    feat_info=feat_info
                )
        
        self.results['attribute_inference'] = results
        return results
    
    def _test_inference_on_labels(self, node_labels, hide_ratio, results, 
                                   label_type="Circles", test_graphsage=True, test_mgn=True, feat_info=None):
        """
        åœ¨ç»™å®šæ ‡ç­¾é›†ä¸Šæµ‹è¯•å±æ€§æ¨æ–­
        
        Args:
            node_labels: èŠ‚ç‚¹æ ‡ç­¾å­—å…¸
            hide_ratio: éšè—æ¯”ä¾‹
            results: ç»“æœåˆ—è¡¨ï¼ˆä¼šè¢«ä¿®æ”¹ï¼‰
            label_type: æ ‡ç­¾ç±»å‹ï¼ˆ"Circles"æˆ–"Feat"ï¼‰
            test_graphsage: æ˜¯å¦æµ‹è¯•GraphSAGE
            feat_info: Featç‰¹å¾ä¿¡æ¯ï¼ˆä»…å½“label_type="Feat"æ—¶ä½¿ç”¨ï¼‰
        """
        # è¿‡æ»¤æ‰ä¸åœ¨å›¾ä¸­çš„èŠ‚ç‚¹
        valid_nodes = [n for n in node_labels.keys() if n in self.G]
        if len(valid_nodes) < len(node_labels):
            skipped = len(node_labels) - len(valid_nodes)
            print(f"âš ï¸  è¿‡æ»¤æ‰ {skipped} ä¸ªä¸åœ¨å›¾ä¸­çš„èŠ‚ç‚¹")
        
        if not valid_nodes:
            print("âš ï¸  æ²¡æœ‰æœ‰æ•ˆçš„èŠ‚ç‚¹ï¼ˆæ‰€æœ‰èŠ‚ç‚¹éƒ½ä¸åœ¨å›¾ä¸­ï¼‰ï¼Œè·³è¿‡æ¨æ–­")
            return
        
        # åªä¿ç•™æœ‰æ•ˆèŠ‚ç‚¹çš„æ ‡ç­¾
        node_labels = {n: node_labels[n] for n in valid_nodes}
        unique_labels = set(node_labels.values())
        
        # éšæœºé€‰æ‹©è¦éšè—çš„èŠ‚ç‚¹
        nodes_list = list(node_labels.keys())
        nodes_to_hide = np.random.choice(nodes_list, 
                                        int(len(nodes_list) * hide_ratio),
                                        replace=False)
        
        known_labels = {n: node_labels[n] for n in nodes_list if n not in nodes_to_hide}
        test_labels = {n: node_labels[n] for n in nodes_to_hide}
        
        print(f"è®­ç»ƒé›†: {len(known_labels)} èŠ‚ç‚¹")
        print(f"æµ‹è¯•é›†: {len(test_labels)} èŠ‚ç‚¹")
        
        # è®¡ç®—éšæœºåŸºå‡†ï¼ˆå¤šæ•°ç±»ï¼‰
        if feat_info and 'class_distribution' in feat_info:
            total = sum(feat_info['class_distribution'].values())
            random_baseline = max(feat_info['class_distribution'].values()) / total
            print(f"éšæœºçŒœæµ‹åŸºå‡†: {random_baseline:.2%}")
        else:
            random_baseline = 1.0 / len(unique_labels) if unique_labels else 0
            if len(unique_labels) > 0:
                print(f"éšæœºçŒœæµ‹åŸºå‡†: {random_baseline:.2%}")
        
        # æ–¹æ³•1: é‚»å±…æŠ•ç¥¨
        print(f"\nã€æ–¹æ³•1ã€‘é‚»å±…æŠ•ç¥¨")
        predictions = {}
        for test_node in test_labels:
            # ç¡®ä¿èŠ‚ç‚¹åœ¨å›¾ä¸­
            if test_node not in self.G:
                continue
            neighbors = list(self.G.neighbors(test_node))
            neighbor_labels = [known_labels[n] for n in neighbors if n in known_labels]
            
            if neighbor_labels:
                most_common = Counter(neighbor_labels).most_common(1)[0][0]
                predictions[test_node] = most_common
            else:
                predictions[test_node] = np.random.choice(list(unique_labels))
        
        correct = sum(1 for n in test_labels if predictions.get(n) == test_labels[n])
        accuracy = correct / len(test_labels) if test_labels else 0
        
        print(f"  - å‡†ç¡®ç‡: {accuracy:.2%}")
        print(f"  - æ­£ç¡®é¢„æµ‹: {correct}/{len(test_labels)}")
        if random_baseline > 0:
            print(f"  - æ”¹è¿›å€æ•°: {accuracy/random_baseline:.2f}x")
        
        results.append({
            'hide_ratio': hide_ratio,
            'method': 'Neighbor-Voting',
            'label_type': label_type,
            'accuracy': accuracy,
            'correct': correct,
            'total': len(test_labels),
            'random_baseline': random_baseline
        })
        
        # æ–¹æ³•2: æ ‡ç­¾ä¼ æ’­
        print(f"\nã€æ–¹æ³•2ã€‘æ ‡ç­¾ä¼ æ’­ç®—æ³•")
        try:
            G_copy = self.G.copy()
            for node in G_copy.nodes():
                if node in known_labels:
                    G_copy.nodes[node]['label'] = known_labels[node]
                else:
                    G_copy.nodes[node]['label'] = None
            
            max_iterations = 10
            for iteration in range(max_iterations):
                updated = False
                for test_node in test_labels:
                    # ç¡®ä¿èŠ‚ç‚¹åœ¨å›¾ä¸­
                    if test_node not in G_copy:
                        continue
                    if G_copy.nodes[test_node]['label'] is None:
                        neighbors = list(G_copy.neighbors(test_node))
                        neighbor_labels = [G_copy.nodes[n]['label'] for n in neighbors 
                                         if G_copy.nodes[n]['label'] is not None]
                        
                        if neighbor_labels:
                            most_common = Counter(neighbor_labels).most_common(1)[0][0]
                            G_copy.nodes[test_node]['label'] = most_common
                            updated = True
                
                if not updated:
                    break
            
            predictions_lp = {}
            for test_node in test_labels:
                pred_label = G_copy.nodes[test_node]['label']
                if pred_label is not None:
                    predictions_lp[test_node] = pred_label
                else:
                    predictions_lp[test_node] = np.random.choice(list(unique_labels))
            
            correct_lp = sum(1 for n in test_labels if predictions_lp.get(n) == test_labels[n])
            accuracy_lp = correct_lp / len(test_labels) if test_labels else 0
            
            print(f"  - å‡†ç¡®ç‡: {accuracy_lp:.2%}")
            print(f"  - æ­£ç¡®é¢„æµ‹: {correct_lp}/{len(test_labels)}")
            print(f"  - è¿­ä»£æ¬¡æ•°: {iteration + 1}")
            if random_baseline > 0:
                print(f"  - æ”¹è¿›å€æ•°: {accuracy_lp/random_baseline:.2f}x")
            
            results.append({
                'hide_ratio': hide_ratio,
                'method': 'Label-Propagation',
                'label_type': label_type,
                'accuracy': accuracy_lp,
                'correct': correct_lp,
                'total': len(test_labels),
                'iterations': iteration + 1,
                'random_baseline': random_baseline
            })
        except Exception as e:
            print(f"  å¤±è´¥: {e}")
        
        # æ–¹æ³•3: GraphSAGEï¼ˆæ”¯æŒCircleså’ŒFeatä¸¤ç§æ ‡ç­¾ï¼‰
        if test_graphsage:
            print(f"\nã€æ–¹æ³•3ã€‘GraphSAGEå›¾ç¥ç»ç½‘ç»œï¼ˆè®¾è®¡è¦æ±‚çš„æ–¹æ³•ï¼‰")
            try:
                from attack.graphsage_attribute_inference import GraphSAGEAttributeInferenceAttack
                import torch
                
                device = 'cuda' if torch.cuda.is_available() else 'cpu'
                print(f"  ä½¿ç”¨è®¾å¤‡: {device}")
                
                # å‡†å¤‡GraphSAGEéœ€è¦çš„attributeså­—å…¸
                # éœ€è¦å°†node_labelsä¸­çš„æ ‡ç­¾æ·»åŠ åˆ°attributesä¸­
                graphsage_attributes = {}
                for node in self.G.nodes():
                    # å¤åˆ¶åŸå§‹å±æ€§ï¼ˆåŒ…æ‹¬featuresï¼‰
                    if node in self.attributes:
                        if isinstance(self.attributes[node], dict):
                            graphsage_attributes[node] = self.attributes[node].copy()
                        else:
                            graphsage_attributes[node] = {}
                    else:
                        graphsage_attributes[node] = {}
                    
                    # æ·»åŠ å½“å‰æµ‹è¯•çš„æ ‡ç­¾ï¼ˆFeatæˆ–Circlesï¼‰
                    # å°†æ ‡ç­¾è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œç¡®ä¿GraphSAGEèƒ½æ­£ç¡®å¤„ç†
                    if node in node_labels:
                        graphsage_attributes[node]['label'] = str(node_labels[node])
                
                # åˆ›å»ºæ”»å‡»å™¨
                graphsage_attacker = GraphSAGEAttributeInferenceAttack(self.G, graphsage_attributes)
                
                # è¿è¡Œæ”»å‡»ï¼ˆtrain_ratio = 1 - hide_ratioï¼‰
                train_ratio = 1.0 - hide_ratio
                graphsage_results = graphsage_attacker.run_attack(
                    train_ratio=train_ratio,
                    epochs=50,  # è®­ç»ƒ50è½®
                    batch_size=64,
                    hidden_dim=64,
                    embed_dim=32,
                    learning_rate=0.01,
                    device=device
                )
                
                if graphsage_results['accuracy'] > 0:
                    print(f"  - å‡†ç¡®ç‡: {graphsage_results['accuracy']:.2%}")
                    print(f"  - F1 (macro): {graphsage_results['f1_macro']:.4f}")
                    print(f"  - F1 (micro): {graphsage_results['f1_micro']:.4f}")
                    print(f"  - è®­ç»ƒé›†: {graphsage_results['train_nodes']} èŠ‚ç‚¹, æµ‹è¯•é›†: {graphsage_results['test_nodes']} èŠ‚ç‚¹")
                    
                    results.append({
                        'hide_ratio': hide_ratio,
                        'method': 'GraphSAGE',
                        'label_type': label_type,
                        'accuracy': graphsage_results['accuracy'],
                        'correct': int(graphsage_results['accuracy'] * graphsage_results['test_nodes']),
                        'total': graphsage_results['test_nodes'],
                        'f1_macro': graphsage_results['f1_macro'],
                        'f1_micro': graphsage_results['f1_micro'],
                        'train_nodes': graphsage_results['train_nodes'],
                        'random_baseline': random_baseline
                    })
                else:
                    print(f"  GraphSAGEå¤±è´¥: {graphsage_results.get('message', 'æœªçŸ¥é”™è¯¯')}")
                    
            except ImportError as e:
                print(f"  âš ï¸  è·³è¿‡GraphSAGEï¼šéœ€è¦å®‰è£…PyTorch (pip install torch)")
            except Exception as e:
                print(f"  âŒ GraphSAGEå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        # æ–¹æ³•4: MGN
        if test_mgn:
            print(f"\nã€æ–¹æ³•4ã€‘MGNå›¾ç¥ç»ç½‘ç»œï¼ˆä¸GraphSAGEå¯¹æ¯”ï¼‰")
            try:
                from attack.graphsage_attribute_inference import MGNAttributeInferenceAttack
                import torch

                device = 'cuda' if torch.cuda.is_available() else 'cpu'
                train_ratio = 1.0 - hide_ratio
                
                # å‡†å¤‡MGNéœ€è¦çš„attributeså­—å…¸ï¼ˆä¸GraphSAGEç›¸åŒï¼‰
                gnn_attributes = {}
                for node in self.G.nodes():
                    if node in self.attributes:
                        if isinstance(self.attributes[node], dict):
                            gnn_attributes[node] = self.attributes[node].copy()
                        else:
                            gnn_attributes[node] = {}
                    else:
                        gnn_attributes[node] = {}
                    
                    if node in node_labels:
                        gnn_attributes[node]['label'] = str(node_labels[node])
                
                mgn_attacker = MGNAttributeInferenceAttack(self.G, gnn_attributes)
                mgn_results = mgn_attacker.run_attack(
                    train_ratio=train_ratio,
                    epochs=50,
                    latent_dim=128,
                    mgn_layers=2,
                    mlp_hidden_layers=1,
                    learning_rate=5e-4,
                    edge_attr_dim=1,
                    device=device
                )

                if mgn_results.get('accuracy', 0) > 0:
                    print(f"  - å‡†ç¡®ç‡: {mgn_results['accuracy']:.2%}")
                    print(f"  - F1 (macro): {mgn_results['f1_macro']:.4f}")
                    print(f"  - F1 (micro): {mgn_results['f1_micro']:.4f}")
                    results.append({
                        'hide_ratio': hide_ratio,
                        'method': 'MGN',
                        'label_type': label_type,
                        'accuracy': mgn_results['accuracy'],
                        'correct': int(mgn_results['accuracy'] * mgn_results.get('test_nodes', 0)),
                        'total': mgn_results.get('test_nodes', 0),
                        'f1_macro': mgn_results['f1_macro'],
                        'f1_micro': mgn_results['f1_micro'],
                        'train_nodes': mgn_results.get('train_nodes', 0),
                        'random_baseline': random_baseline
                    })
                else:
                    print(f"  MGNå¤±è´¥: {mgn_results.get('message', 'æœªçŸ¥é”™è¯¯')}")
            except Exception as e:
                print(f"  âŒ MGNå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
    
    def run_robustness_test(self):
        """è¿è¡Œé²æ£’æ€§æµ‹è¯•"""
        print(f"\n{'='*70}")
        print("ã€é˜¶æ®µ3ã€‘é²æ£’æ€§æµ‹è¯•")
        print(f"{'='*70}")
        
        try:
            robustness = RobustnessSimulator(self.G)
            # å¢åŠ æµ‹è¯•ç‚¹ï¼Œè®©æ›²çº¿æ›´å¹³æ»‘
            incomplete_ratios = [0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5]
            
            # ç”Ÿæˆæ‰€æœ‰ä¸å®Œæ•´å›¾
            incomplete_graphs = robustness.generate_incomplete_graphs(incomplete_ratios)
            
            results = []
            for ratio in incomplete_ratios:
                print(f"\næµ‹è¯•ç¼ºå¤±ç‡: {ratio:.0%}")
                G_incomplete = incomplete_graphs[ratio]
                
                # ç®€å•çš„å»åŒ¿ååŒ–æµ‹è¯•
                anonymizer = GraphAnonymizer(G_incomplete)
                G_anon, mapping = anonymizer.anonymize_with_perturbation(
                    edge_retention_ratio=0.9,
                    noise_edge_ratio=0.05
                )
                
                ground_truth = {orig: mapping[orig] for orig in G_incomplete.nodes() if orig in mapping}
                
                baseline = BaselineMatcher(G_incomplete, G_anon, similarity_metric='cosine')
                predictions = baseline.match_by_features(top_k=10)
                metrics = DeAnonymizationMetrics.calculate_all_metrics(predictions, ground_truth)
                
                print(f"  - Top-1å‡†ç¡®ç‡: {metrics['accuracy']:.2%}")
                
                results.append({
                    'missing_ratio': ratio,
                    'accuracy': metrics['accuracy']
                })
            
            self.results['robustness'] = results
            return results
        except Exception as e:
            print(f"é²æ£’æ€§æµ‹è¯•å¤±è´¥: {e}")
            return []
    
    def run_defense_experiment(self, epsilon_values=None):
        """è¿è¡Œå¤šç§é˜²å¾¡å®éªŒ"""
        print(f"\n{'='*70}")
        print("ã€é˜¶æ®µ4ã€‘éšç§é˜²å¾¡å®éªŒ")
        print(f"{'='*70}")
        
        if epsilon_values is None:
            # å¢åŠ æµ‹è¯•ç‚¹ï¼Œè®©æ›²çº¿æ›´å¹³æ»‘
            epsilon_values = [0.1, 0.3, 0.5, 0.7, 1.0, 1.5, 2.0, 3.0, 5.0]
        
        try:
            results = []
            for epsilon in epsilon_values:
                print(f"\næµ‹è¯• Îµ = {epsilon}")
                
                dp_defense = DifferentialPrivacyDefense(self.G, epsilon=epsilon)
                G_protected = dp_defense.add_noise_edge_perturbation()
                
                # è¯„ä¼°æ•ˆç”¨ä¿æŒ
                evaluator = PrivacyUtilityEvaluator(self.G, G_protected)
                structural_loss = evaluator.calculate_graph_structural_loss()
                
                # è®¡ç®—æ•ˆç”¨ä¿æŒç‡ï¼ˆ1 - æŸå¤±ï¼‰
                edge_preservation = structural_loss['edges_unchanged'] / self.G.number_of_edges() if self.G.number_of_edges() > 0 else 0
                utility_score = 1 - structural_loss['l1_distance']  # åŸºäºL1è·ç¦»çš„æ•ˆç”¨å¾—åˆ†
                
                print(f"  - èŠ‚ç‚¹æ•°: {G_protected.number_of_nodes()}")
                print(f"  - è¾¹æ•°: {G_protected.number_of_edges()}")
                print(f"  - è¾¹ä¿ç•™ç‡: {edge_preservation:.2%}")
                print(f"  - æ•ˆç”¨å¾—åˆ†: {utility_score:.2%}")
                print(f"  - åº¦åˆ†å¸ƒMAE: {structural_loss['degree_mae']:.2f}")
                
                results.append({
                    'epsilon': epsilon,
                    'protected_nodes': G_protected.number_of_nodes(),
                    'protected_edges': G_protected.number_of_edges(),
                    'edge_preservation': edge_preservation,
                    'utility_score': utility_score,
                    'structural_loss': structural_loss
                })
            
            self.results['defense'] = results
            
            # æ·»åŠ å…¶ä»–é˜²å¾¡æ–¹æ³•çš„æµ‹è¯•
            print(f"\n{'='*70}")
            print("ã€é¢å¤–é˜²å¾¡ç­–ç•¥ã€‘K-åŒ¿åæ€§å’Œç‰¹å¾æ‰°åŠ¨")
            print(f"{'='*70}")
            
            # K-åŒ¿åæ€§é˜²å¾¡æµ‹è¯•
            try:
                from defense import KAnonymityDefense
                print(f"\næµ‹è¯• K-åŒ¿åæ€§é˜²å¾¡ (k=3)")
                k_defense = KAnonymityDefense(self.G, k=3)
                G_k_anon = k_defense.apply_k_anonymity(method='add_edges')
                k_score = k_defense.calculate_anonymity_score(G_k_anon)
                print(f"  - K-åŒ¿åæ€§å¾—åˆ†: {k_score:.2%}")
                print(f"  - è¾¹æ•°å˜åŒ–: {G_k_anon.number_of_edges() - self.G.number_of_edges():+d}")
            except Exception as e:
                print(f"  K-åŒ¿åæ€§æµ‹è¯•å¤±è´¥: {e}")
            
            # ç‰¹å¾æ‰°åŠ¨é˜²å¾¡ï¼ˆå¦‚æœå›¾æœ‰ç‰¹å¾ï¼‰
            has_features = any('feature' in self.G.nodes[n] for n in list(self.G.nodes())[:10])
            if has_features:
                try:
                    from defense import FeaturePerturbationDefense
                    print(f"\næµ‹è¯•ç‰¹å¾æ‰°åŠ¨é˜²å¾¡")
                    feat_defense = FeaturePerturbationDefense(self.G, noise_level=0.1)
                    G_perturbed = feat_defense.apply_gaussian_noise(seed=42)
                    utilities = feat_defense.calculate_feature_utility(self.G, G_perturbed)
                    print(f"  - ä½™å¼¦ç›¸ä¼¼åº¦: {utilities.get('mean_cosine_similarity', 0):.4f}")
                    print(f"  - ç›¸å¯¹è¯¯å·®: {utilities.get('mean_relative_error', 0):.4f}")
                except Exception as e:
                    print(f"  ç‰¹å¾æ‰°åŠ¨æµ‹è¯•å¤±è´¥: {e}")
            
            return results
        except Exception as e:
            print(f"é˜²å¾¡å®éªŒå¤±è´¥: {e}")
            return []
    
    def print_summary(self):
        """æ‰“å°å®éªŒæ€»ç»“"""
        print(f"\n{'='*70}")
        print("å®éªŒç»“æœæ€»ç»“")
        print(f"{'='*70}")
        
        # å»åŒ¿ååŒ–ç»“æœ
        if 'deanonymization' in self.results:
            print(f"\nã€èº«ä»½å»åŒ¿ååŒ–ç»“æœã€‘")
            print(f"{'åŒ¿ååŒ–å¼ºåº¦':<12} {'æ–¹æ³•':<20} {'Top-1':<8} {'P@5':<8} {'MRR':<8}")
            print("-"*60)
            for r in self.results['deanonymization']:
                print(f"{r['level']:<12} {r['method']:<20} "
                      f"{r['accuracy']:>6.2%} {r.get('precision@5', 0):>6.2%} {r.get('mrr', 0):>6.4f}")
        
        # å±æ€§æ¨æ–­ç»“æœ
        if 'attribute_inference' in self.results:
            print(f"\nã€å±æ€§æ¨æ–­ç»“æœã€‘")
            print(f"{'éšè—æ¯”ä¾‹':<12} {'æ–¹æ³•':<20} {'å‡†ç¡®ç‡':<10}")
            print("-"*45)
            for r in self.results['attribute_inference']:
                print(f"{r['hide_ratio']:<12.0%} {r['method']:<20} {r['accuracy']:>8.2%}")
        
        # é²æ£’æ€§ç»“æœ
        if 'robustness' in self.results:
            print(f"\nã€é²æ£’æ€§æµ‹è¯•ç»“æœã€‘")
            print(f"{'ç¼ºå¤±ç‡':<12} {'å‡†ç¡®ç‡':<10}")
            print("-"*25)
            for r in self.results['robustness']:
                print(f"{r['missing_ratio']:<12.0%} {r['accuracy']:>8.2%}")
        
        # é˜²å¾¡ç»“æœ
        if 'defense' in self.results:
            print(f"\nã€å·®åˆ†éšç§é˜²å¾¡ç»“æœã€‘")
            print(f"{'Epsilon':<12} {'è¾¹ä¿ç•™ç‡':<12} {'æ•ˆç”¨å¾—åˆ†':<12}")
            print("-"*40)
            for r in self.results['defense']:
                edge_pres = r.get('edge_preservation', 0)
                utility = r.get('utility_score', 0)
                print(f"{r['epsilon']:<12.2f} {edge_pres:>10.2%} {utility:>10.2%}")
    
    def save_results(self):
        """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{self.dataset_name}"
        if self.ego_id:
            filename += f"_ego{self.ego_id}"
        filename += f"_{timestamp}.json"
        
        filepath = os.path.join(self.output_dir, filename)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        return filepath


def main():
    parser = argparse.ArgumentParser(
        description="ç»Ÿä¸€å®éªŒæ¡†æ¶ - æ”¯æŒæ‰€æœ‰æ•°æ®é›†å’Œæ‰€æœ‰å®éªŒæ¨¡å¼"
    )
    
    # æ•°æ®é›†å‚æ•°
    parser.add_argument(
        '--dataset',
        type=str,
        required=True,
        choices=['facebook', 'facebook_ego', 'cora', 'citeseer', 'weibo'],
        help='æ•°æ®é›†åç§°'
    )
    parser.add_argument(
        '--ego_id',
        type=str,
        default='0',
        help='Egoç½‘ç»œID (ä»…ç”¨äºfacebook_ego)'
    )
    
    # å®éªŒæ¨¡å¼
    parser.add_argument(
        '--mode',
        type=str,
        default='all',
        choices=['quick', 'attack', 'attribute', 'robustness', 'defense', 'all'],
        help='å®éªŒæ¨¡å¼: quick(å¿«é€Ÿ), attack(å»åŒ¿ååŒ–), attribute(å±æ€§æ¨æ–­), robustness(é²æ£’æ€§), defense(é˜²å¾¡), all(å…¨éƒ¨)'
    )
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument(
        '--output',
        type=str,
        default='results/unified',
        help='è¾“å‡ºç›®å½•'
    )
    
    parser.add_argument(
        '--save',
        action='store_true',
        default=True,
        help='ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶ï¼ˆé»˜è®¤å¼€å¯ï¼‰'
    )
    
    parser.add_argument(
        '--no-save',
        dest='save',
        action='store_false',
        help='ä¸ä¿å­˜ç»“æœï¼ˆä»…ç»ˆç«¯æ˜¾ç¤ºï¼‰'
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºå®éªŒ
    experiment = UnifiedExperiment(
        dataset_name=args.dataset,
        ego_id=args.ego_id if args.dataset == 'facebook_ego' else None,
        output_dir=args.output
    )
    
    # æ‰“å°æ•°æ®é›†ä¿¡æ¯
    experiment.print_dataset_info()
    
    # æ ¹æ®æ¨¡å¼è¿è¡Œå®éªŒ
    if args.mode == 'quick':
        # å¿«é€Ÿæµ‹è¯•ï¼šåªæµ‹è¯•ä¸€ç§åŒ¿ååŒ–å¼ºåº¦
        experiment.run_deanonymization_attack(
            anonymization_levels=[(0.95, 0.02, "æ¸©å’Œ")]
        )
    
    elif args.mode == 'attack':
        # å®Œæ•´å»åŒ¿ååŒ–æ”»å‡»
        experiment.run_deanonymization_attack()
    
    elif args.mode == 'attribute':
        # å±æ€§æ¨æ–­
        experiment.run_attribute_inference()
    
    elif args.mode == 'robustness':
        # é²æ£’æ€§æµ‹è¯•
        experiment.run_robustness_test()
    
    elif args.mode == 'defense':
        # å·®åˆ†éšç§é˜²å¾¡
        experiment.run_defense_experiment()
    
    elif args.mode == 'all':
        # å®Œæ•´å®éªŒ
        experiment.run_deanonymization_attack()
        experiment.run_attribute_inference()
        experiment.run_robustness_test()
        experiment.run_defense_experiment()
    
    # æ‰“å°æ€»ç»“
    experiment.print_summary()
    
    # ä¿å­˜ç»“æœï¼ˆé»˜è®¤ä¿å­˜ï¼Œé™¤éä½¿ç”¨--no-saveï¼‰
    if args.save:
        filepath = experiment.save_results()
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {filepath}")
    else:
        print(f"\nğŸ’¡ ç»“æœæœªä¿å­˜ï¼ˆä½¿ç”¨ --no-save å‚æ•°ï¼‰")
    
    print(f"\n{'='*70}")
    print("å®éªŒå®Œæˆï¼")
    print(f"{'='*70}")


if __name__ == "__main__":
    main()


