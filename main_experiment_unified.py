"""
ç»Ÿä¸€å®éªŒè„šæœ¬ - æ•´åˆæ‰€æœ‰å®éªŒåŠŸèƒ½
æ”¯æŒæ‰€æœ‰æ•°æ®é›†å’Œæ‰€æœ‰å®éªŒæ¨¡å¼

ä½¿ç”¨ç¤ºä¾‹:
  # Facebook Combined - å®Œæ•´å®éªŒ
  python main_experiment_unified.py --dataset facebook --mode all
  
  # Facebook Ego - ä¼˜åŒ–æ”»å‡»
  python main_experiment_unified.py --dataset facebook_ego --ego_id 0 --mode attack
  
  # Cora - å±æ€§æ¨æ–­
  python main_experiment_unified.py --dataset cora --mode attribute_inference
  
  # å¿«é€Ÿæµ‹è¯•
  python main_experiment_unified.py --dataset facebook_ego --ego_id 698 --mode quick
"""

import argparse
import os
import sys
import numpy as np
import networkx as nx
from datetime import datetime
from collections import defaultdict, Counter
import json

# å¯¼å…¥æ‰€æœ‰å¿…è¦çš„æ¨¡å—
from data.dataset_loader import DatasetLoader
from attack.embedding_match import EmbeddingMatcher
from attack.baseline_match import BaselineMatcher
from attack.attribute_inference import AttributeInferenceAttack, LabelPropagationAttack
from attack.neighborhood_sampler import NeighborhoodSampler, RobustnessSimulator
from defense.differential_privacy import DifferentialPrivacyDefense, PrivacyUtilityEvaluator
from utils.comprehensive_metrics import (
    DeAnonymizationMetrics,
    AttributeInferenceMetrics,
    RobustnessMetrics,
    PrivacyMetrics,
    ComprehensiveEvaluator
)
from preprocessing.anonymizer import GraphAnonymizer
from models.deepwalk import DeepWalkModel
from models.feature_extractor import FeatureExtractor


class UnifiedExperiment:
    """ç»Ÿä¸€å®éªŒæ¡†æ¶"""
    
    def __init__(self, dataset_name, ego_id=None, output_dir="results/unified"):
        """
        åˆå§‹åŒ–ç»Ÿä¸€å®éªŒ
        
        Args:
            dataset_name: æ•°æ®é›†åç§°
            ego_id: egoç½‘ç»œID (ä»…ç”¨äºfacebook_ego)
            output_dir: è¾“å‡ºç›®å½•
        """
        self.dataset_name = dataset_name
        self.ego_id = ego_id
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
        
        # åŠ è½½æ•°æ®
        self.G, self.attributes = self._load_dataset()
        
        # ç»“æœå­˜å‚¨
        self.results = {
            'dataset': dataset_name,
            'ego_id': ego_id,
            'timestamp': datetime.now().isoformat(),
            'graph_stats': self._get_graph_stats()
        }
    
    def _load_dataset(self):
        """åŠ è½½æ•°æ®é›†"""
        loader = DatasetLoader()
        
        if self.dataset_name == 'facebook':
            return loader._load_facebook_combined()
        elif self.dataset_name == 'facebook_ego':
            ego_id = self.ego_id or '0'
            return loader.load_facebook(ego_network=ego_id)
        elif self.dataset_name == 'cora':
            return loader.load_cora()
        elif self.dataset_name == 'citeseer':
            return loader.load_citeseer()
        elif self.dataset_name == 'weibo':
            return loader.load_weibo()
        else:
            raise ValueError(f"æœªçŸ¥æ•°æ®é›†: {self.dataset_name}")
    
    def _get_graph_stats(self):
        """è·å–å›¾ç»Ÿè®¡ä¿¡æ¯"""
        stats = {
            'nodes': self.G.number_of_nodes(),
            'edges': self.G.number_of_edges(),
            'avg_degree': 2 * self.G.number_of_edges() / self.G.number_of_nodes() if self.G.number_of_nodes() > 0 else 0,
            'density': nx.density(self.G),
        }
        
        if self.attributes:
            stats['nodes_with_attributes'] = len(self.attributes)
            # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡ç­¾
            has_labels = any('label' in attr for attr in self.attributes.values() if isinstance(attr, dict))
            has_circles = any('circles' in attr for attr in self.attributes.values() if isinstance(attr, dict))
            has_features = any('features' in attr for attr in self.attributes.values() if isinstance(attr, dict))
            
            stats['has_labels'] = has_labels
            stats['has_circles'] = has_circles
            stats['has_features'] = has_features
        
        return stats
    
    def print_dataset_info(self):
        """æ‰“å°æ•°æ®é›†ä¿¡æ¯"""
        print(f"\n{'='*70}")
        print(f"ç»Ÿä¸€å®éªŒæ¡†æ¶")
        print(f"æ•°æ®é›†: {self.dataset_name}")
        if self.ego_id:
            print(f"Egoç½‘ç»œID: {self.ego_id}")
        print(f"{'='*70}")
        
        print(f"\næ•°æ®é›†ä¿¡æ¯:")
        print(f"  - èŠ‚ç‚¹æ•°: {self.results['graph_stats']['nodes']}")
        print(f"  - è¾¹æ•°: {self.results['graph_stats']['edges']}")
        print(f"  - å¹³å‡åº¦: {self.results['graph_stats']['avg_degree']:.2f}")
        print(f"  - å¯†åº¦: {self.results['graph_stats']['density']:.4f}")
        
        if self.attributes:
            print(f"  - æœ‰å±æ€§çš„èŠ‚ç‚¹æ•°: {self.results['graph_stats']['nodes_with_attributes']}")
            if self.results['graph_stats'].get('has_labels'):
                print(f"  - âœ… åŒ…å«èŠ‚ç‚¹æ ‡ç­¾")
            if self.results['graph_stats'].get('has_circles'):
                print(f"  - âœ… åŒ…å«ç¤¾äº¤åœˆæ ‡ç­¾")
            if self.results['graph_stats'].get('has_features'):
                print(f"  - âœ… åŒ…å«èŠ‚ç‚¹ç‰¹å¾å‘é‡")
    
    def run_deanonymization_attack(self, anonymization_levels=None):
        """
        è¿è¡Œå»åŒ¿ååŒ–æ”»å‡»å®éªŒ
        
        Args:
            anonymization_levels: åŒ¿ååŒ–å¼ºåº¦åˆ—è¡¨
        """
        print(f"\n{'='*70}")
        print("ã€é˜¶æ®µ1ã€‘èº«ä»½å»åŒ¿ååŒ–æ”»å‡»")
        print(f"{'='*70}")
        
        if anonymization_levels is None:
            anonymization_levels = [
                (0.95, 0.02, "æ¸©å’Œ"),
                (0.90, 0.05, "ä¸­ç­‰"),
                (0.85, 0.10, "è¾ƒå¼º"),
            ]
        
        results = []
        
        for edge_retention, noise_ratio, level_name in anonymization_levels:
            print(f"\n{'='*60}")
            print(f"åŒ¿ååŒ–å¼ºåº¦: {level_name} (ä¿ç•™{edge_retention:.0%}è¾¹, æ·»åŠ {noise_ratio:.0%}å™ªå£°)")
            print(f"{'='*60}")
            
            # åŒ¿ååŒ–
            anonymizer = GraphAnonymizer(self.G)
            G_anon, node_mapping = anonymizer.anonymize_with_perturbation(
                edge_retention_ratio=edge_retention,
                noise_edge_ratio=noise_ratio
            )
            
            ground_truth = {orig: node_mapping[orig] for orig in self.G.nodes() if orig in node_mapping}
            print(f"åŒ¿åå›¾: {G_anon.number_of_nodes()} èŠ‚ç‚¹, {G_anon.number_of_edges()} è¾¹")
            
            # æ–¹æ³•1: Baselineè´ªå¿ƒåŒ¹é…
            print(f"\nã€æ–¹æ³•1ã€‘Baselineè´ªå¿ƒåŒ¹é…")
            try:
                baseline = BaselineMatcher(self.G, G_anon, similarity_metric='cosine')
                predictions = baseline.match_by_features(top_k=20)
                metrics = DeAnonymizationMetrics.calculate_all_metrics(predictions, ground_truth)
                
                print(f"  - Top-1å‡†ç¡®ç‡: {metrics['accuracy']:.2%}")
                print(f"  - Precision@5: {metrics['precision@5']:.2%}")
                print(f"  - Precision@10: {metrics['precision@10']:.2%}")
                print(f"  - MRR: {metrics['mrr']:.4f}")
                
                results.append({
                    'level': level_name,
                    'method': 'Baseline-Greedy',
                    **metrics
                })
            except Exception as e:
                print(f"  å¤±è´¥: {e}")
            
            # æ–¹æ³•2: åŒˆç‰™åˆ©ç®—æ³•
            print(f"\nã€æ–¹æ³•2ã€‘åŒˆç‰™åˆ©ç®—æ³•ï¼ˆæœ€ä¼˜åŒ¹é…ï¼‰")
            try:
                from scipy.optimize import linear_sum_assignment
                from sklearn.preprocessing import StandardScaler
                from sklearn.metrics.pairwise import cosine_similarity
                
                extractor = FeatureExtractor()
                nodes_orig = sorted(list(self.G.nodes()))
                nodes_anon = sorted(list(G_anon.nodes()))
                
                features_orig = extractor.extract_node_features(self.G, nodes_orig)
                features_anon = extractor.extract_node_features(G_anon, nodes_anon)
                
                scaler = StandardScaler()
                features_orig = scaler.fit_transform(features_orig)
                features_anon = scaler.transform(features_anon)
                
                similarity = cosine_similarity(features_orig, features_anon)
                
                predictions = {}
                for i, orig_node in enumerate(nodes_orig):
                    top_indices = np.argsort(similarity[i])[::-1][:20]
                    anon_nodes = [nodes_anon[idx] for idx in top_indices if idx < len(nodes_anon)]
                    predictions[orig_node] = anon_nodes
                
                metrics = DeAnonymizationMetrics.calculate_all_metrics(predictions, ground_truth)
                
                print(f"  - Top-1å‡†ç¡®ç‡: {metrics['accuracy']:.2%}")
                print(f"  - Precision@5: {metrics['precision@5']:.2%}")
                print(f"  - Precision@10: {metrics['precision@10']:.2%}")
                print(f"  - MRR: {metrics['mrr']:.4f}")
                
                results.append({
                    'level': level_name,
                    'method': 'Hungarian',
                    **metrics
                })
            except Exception as e:
                print(f"  å¤±è´¥: {e}")
            
            # æ–¹æ³•3: èŠ‚ç‚¹ç‰¹å¾åŒ¹é…ï¼ˆå¦‚æœæœ‰ç‰¹å¾ï¼‰
            if self.attributes and self.results['graph_stats'].get('has_features'):
                print(f"\nã€æ–¹æ³•3ã€‘èŠ‚ç‚¹ç‰¹å¾å‘é‡åŒ¹é…")
                try:
                    feature_dict_orig = {}
                    for node in self.G.nodes():
                        if node in self.attributes and 'features' in self.attributes[node]:
                            feature_dict_orig[node] = self.attributes[node]['features']
                    
                    if len(feature_dict_orig) > 0:
                        nodes_with_feat = list(feature_dict_orig.keys())
                        feat_matrix_orig = np.array([feature_dict_orig[n] for n in nodes_with_feat])
                        
                        feat_matrix_anon = []
                        nodes_anon_with_feat = []
                        for orig_node in nodes_with_feat:
                            if orig_node in ground_truth:
                                anon_node = ground_truth[orig_node]
                                nodes_anon_with_feat.append(anon_node)
                                feat_matrix_anon.append(feature_dict_orig[orig_node])
                        
                        feat_matrix_anon = np.array(feat_matrix_anon).astype(float)
                        noise = np.random.binomial(1, 0.05, feat_matrix_anon.shape)
                        feat_matrix_anon = np.abs(feat_matrix_anon - noise)
                        
                        from sklearn.metrics.pairwise import cosine_similarity
                        similarity = cosine_similarity(feat_matrix_orig, feat_matrix_anon)
                        
                        predictions = {}
                        for i, orig_node in enumerate(nodes_with_feat):
                            top_indices = np.argsort(similarity[i])[::-1][:20]
                            anon_nodes = [nodes_anon_with_feat[idx] for idx in top_indices 
                                         if idx < len(nodes_anon_with_feat)]
                            predictions[orig_node] = anon_nodes
                        
                        partial_truth = {k: v for k, v in ground_truth.items() if k in predictions}
                        metrics = DeAnonymizationMetrics.calculate_all_metrics(predictions, partial_truth)
                        
                        print(f"  - Top-1å‡†ç¡®ç‡: {metrics['accuracy']:.2%}")
                        print(f"  - Precision@5: {metrics['precision@5']:.2%}")
                        print(f"  - MRR: {metrics['mrr']:.4f}")
                        
                        results.append({
                            'level': level_name,
                            'method': 'Node-Features',
                            **metrics
                        })
                except Exception as e:
                    print(f"  å¤±è´¥: {e}")
            
            # æ–¹æ³•4: DeepWalkå›¾åµŒå…¥ï¼ˆåœ¨æ‰€æœ‰åŒ¿ååŒ–å¼ºåº¦ä¸‹æµ‹è¯•ï¼‰
            print(f"\nã€æ–¹æ³•4ã€‘DeepWalkå›¾åµŒå…¥ï¼ˆè®¾è®¡è¦æ±‚çš„æ–¹æ³•ï¼‰")
            try:
                from models.deepwalk import DeepWalkModel
                
                nodes_orig = sorted(list(self.G.nodes()))
                nodes_anon = sorted(list(G_anon.nodes()))
                
                # ä½¿ç”¨ä¼˜åŒ–çš„å‚æ•°
                deepwalk = DeepWalkModel(
                    dimensions=256,      # å¢åŠ ç»´åº¦
                    walk_length=100,     # å¢åŠ æ¸¸èµ°é•¿åº¦
                    num_walks=20,        # å¢åŠ æ¸¸èµ°æ¬¡æ•°
                    window_size=10,
                    workers=4
                )
                
                print("  è®­ç»ƒåŸå§‹å›¾åµŒå…¥...")
                emb_orig = deepwalk.train(self.G)
                print("  è®­ç»ƒåŒ¿åå›¾åµŒå…¥...")
                emb_anon = deepwalk.train(G_anon)
                
                from attack.embedding_match import EmbeddingMatcher
                embedder = EmbeddingMatcher(self.G, G_anon)
                embedder.embeddings_orig = emb_orig
                embedder.embeddings_anon = emb_anon
                
                predictions_idx = embedder.match_by_similarity(top_k=20)
                
                # è½¬æ¢ä¸ºèŠ‚ç‚¹IDæ ¼å¼
                predictions = {}
                for orig_idx, anon_indices in predictions_idx.items():
                    if orig_idx < len(nodes_orig):
                        orig_node = nodes_orig[orig_idx]
                        anon_nodes = [nodes_anon[idx] for idx in anon_indices 
                                     if idx < len(nodes_anon)]
                        predictions[orig_node] = anon_nodes
                
                metrics = DeAnonymizationMetrics.calculate_all_metrics(predictions, ground_truth)
                
                print(f"  - Top-1å‡†ç¡®ç‡: {metrics['accuracy']:.2%}")
                print(f"  - Precision@5: {metrics['precision@5']:.2%}")
                print(f"  - Precision@10: {metrics['precision@10']:.2%}")
                print(f"  - MRR: {metrics['mrr']:.4f}")
                
                results.append({
                    'level': level_name,
                    'method': 'DeepWalk',
                    **metrics
                })
            except Exception as e:
                print(f"  å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        
        self.results['deanonymization'] = results
        return results
    
    def run_attribute_inference(self, hide_ratios=None):
        """
        è¿è¡Œå±æ€§æ¨æ–­æ”»å‡»
        
        Args:
            hide_ratios: éšè—æ ‡ç­¾çš„æ¯”ä¾‹åˆ—è¡¨
        """
        print(f"\n{'='*70}")
        print("ã€é˜¶æ®µ2ã€‘å±æ€§æ¨æ–­æ”»å‡»")
        print(f"{'='*70}")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡ç­¾
        has_labels = self.results['graph_stats'].get('has_labels')
        has_circles = self.results['graph_stats'].get('has_circles')
        
        if not (has_labels or has_circles):
            print("âš ï¸  è¯¥æ•°æ®é›†æ²¡æœ‰èŠ‚ç‚¹æ ‡ç­¾ï¼Œè·³è¿‡å±æ€§æ¨æ–­å®éªŒ")
            return []
        
        if hide_ratios is None:
            hide_ratios = [0.3, 0.5, 0.7]
        
        results = []
        
        # å‡†å¤‡æ ‡ç­¾æ•°æ®
        node_labels = {}
        if has_circles:
            # ä½¿ç”¨ç¤¾äº¤åœˆæ ‡ç­¾
            for node in self.G.nodes():
                if node in self.attributes and 'circles' in self.attributes[node]:
                    circles = self.attributes[node]['circles']
                    if circles:
                        node_labels[node] = circles[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªåœˆä½œä¸ºæ ‡ç­¾
        elif has_labels:
            # ä½¿ç”¨å¸¸è§„æ ‡ç­¾
            for node in self.G.nodes():
                if node in self.attributes and 'label' in self.attributes[node]:
                    node_labels[node] = self.attributes[node]['label']
        
        if not node_labels:
            print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„æ ‡ç­¾æ•°æ®")
            return []
        
        print(f"æœ‰æ ‡ç­¾çš„èŠ‚ç‚¹æ•°: {len(node_labels)}")
        unique_labels = set(node_labels.values())
        print(f"å”¯ä¸€æ ‡ç­¾æ•°: {len(unique_labels)}")
        
        for hide_ratio in hide_ratios:
            print(f"\n{'='*60}")
            print(f"éšè— {hide_ratio:.0%} èŠ‚ç‚¹çš„æ ‡ç­¾")
            print(f"{'='*60}")
            
            # éšæœºé€‰æ‹©è¦éšè—çš„èŠ‚ç‚¹
            nodes_list = list(node_labels.keys())
            nodes_to_hide = np.random.choice(nodes_list, 
                                            int(len(nodes_list) * hide_ratio),
                                            replace=False)
            
            known_labels = {n: node_labels[n] for n in nodes_list if n not in nodes_to_hide}
            test_labels = {n: node_labels[n] for n in nodes_to_hide}
            
            print(f"è®­ç»ƒé›†: {len(known_labels)} èŠ‚ç‚¹")
            print(f"æµ‹è¯•é›†: {len(test_labels)} èŠ‚ç‚¹")
            
            # æ–¹æ³•1: é‚»å±…æŠ•ç¥¨
            print(f"\nã€æ–¹æ³•1ã€‘é‚»å±…æŠ•ç¥¨")
            predictions = {}
            for test_node in test_labels:
                neighbors = list(self.G.neighbors(test_node))
                neighbor_labels = [known_labels[n] for n in neighbors if n in known_labels]
                
                if neighbor_labels:
                    most_common = Counter(neighbor_labels).most_common(1)[0][0]
                    predictions[test_node] = most_common
                else:
                    predictions[test_node] = np.random.choice(list(unique_labels))
            
            correct = sum(1 for n in test_labels if predictions.get(n) == test_labels[n])
            accuracy = correct / len(test_labels) if test_labels else 0
            
            print(f"  - å‡†ç¡®ç‡: {accuracy:.2%}")
            print(f"  - æ­£ç¡®é¢„æµ‹: {correct}/{len(test_labels)}")
            
            results.append({
                'hide_ratio': hide_ratio,
                'method': 'Neighbor-Voting',
                'accuracy': accuracy,
                'correct': correct,
                'total': len(test_labels)
            })
            
            # æ–¹æ³•2: æ ‡ç­¾ä¼ æ’­
            print(f"\nã€æ–¹æ³•2ã€‘æ ‡ç­¾ä¼ æ’­ç®—æ³•")
            try:
                G_copy = self.G.copy()
                for node in G_copy.nodes():
                    if node in known_labels:
                        G_copy.nodes[node]['label'] = known_labels[node]
                    else:
                        G_copy.nodes[node]['label'] = None
                
                max_iterations = 10
                for iteration in range(max_iterations):
                    updated = False
                    for test_node in test_labels:
                        if G_copy.nodes[test_node]['label'] is None:
                            neighbors = list(G_copy.neighbors(test_node))
                            neighbor_labels = [G_copy.nodes[n]['label'] for n in neighbors 
                                             if G_copy.nodes[n]['label'] is not None]
                            
                            if neighbor_labels:
                                most_common = Counter(neighbor_labels).most_common(1)[0][0]
                                G_copy.nodes[test_node]['label'] = most_common
                                updated = True
                    
                    if not updated:
                        break
                
                predictions_lp = {}
                for test_node in test_labels:
                    pred_label = G_copy.nodes[test_node]['label']
                    if pred_label is not None:
                        predictions_lp[test_node] = pred_label
                    else:
                        predictions_lp[test_node] = np.random.choice(list(unique_labels))
                
                correct_lp = sum(1 for n in test_labels if predictions_lp.get(n) == test_labels[n])
                accuracy_lp = correct_lp / len(test_labels) if test_labels else 0
                
                print(f"  - å‡†ç¡®ç‡: {accuracy_lp:.2%}")
                print(f"  - æ­£ç¡®é¢„æµ‹: {correct_lp}/{len(test_labels)}")
                print(f"  - è¿­ä»£æ¬¡æ•°: {iteration + 1}")
                
                results.append({
                    'hide_ratio': hide_ratio,
                    'method': 'Label-Propagation',
                    'accuracy': accuracy_lp,
                    'correct': correct_lp,
                    'total': len(test_labels),
                    'iterations': iteration + 1
                })
            except Exception as e:
                print(f"  å¤±è´¥: {e}")
            
            # æ–¹æ³•3: GraphSAGEå›¾ç¥ç»ç½‘ç»œï¼ˆå¯¹æ¯ä¸ªéšè—æ¯”ä¾‹éƒ½è¿è¡Œï¼‰
            print(f"\nã€æ–¹æ³•3ã€‘GraphSAGEå›¾ç¥ç»ç½‘ç»œï¼ˆè®¾è®¡è¦æ±‚çš„æ–¹æ³•ï¼‰")
            try:
                from attack.graphsage_attribute_inference import GraphSAGEAttributeInferenceAttack
                import torch
                
                # æ£€æŸ¥æ˜¯å¦æœ‰GPUï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡æ—¶æ‰“å°ï¼‰
                if hide_ratio == hide_ratios[0]:
                    device = 'cuda' if torch.cuda.is_available() else 'cpu'
                    print(f"  ä½¿ç”¨è®¾å¤‡: {device}")
                
                device = 'cuda' if torch.cuda.is_available() else 'cpu'
                
                # åˆ›å»ºæ”»å‡»å™¨
                graphsage_attacker = GraphSAGEAttributeInferenceAttack(self.G, self.attributes)
                
                # è¿è¡Œæ”»å‡»ï¼ˆtrain_ratio = 1 - hide_ratioï¼‰
                train_ratio = 1.0 - hide_ratio
                graphsage_results = graphsage_attacker.run_attack(
                    train_ratio=train_ratio,
                    epochs=50,  # è®­ç»ƒ50è½®
                    batch_size=64,
                    hidden_dim=64,
                    embed_dim=32,
                    learning_rate=0.01,
                    device=device
                )
                
                if graphsage_results['accuracy'] > 0:
                    print(f"  - å‡†ç¡®ç‡: {graphsage_results['accuracy']:.2%}")
                    print(f"  - F1 (macro): {graphsage_results['f1_macro']:.4f}")
                    print(f"  - F1 (micro): {graphsage_results['f1_micro']:.4f}")
                    print(f"  - è®­ç»ƒé›†: {graphsage_results['train_nodes']} èŠ‚ç‚¹, æµ‹è¯•é›†: {graphsage_results['test_nodes']} èŠ‚ç‚¹")
                    
                    results.append({
                        'hide_ratio': hide_ratio,
                        'method': 'GraphSAGE',
                        'accuracy': graphsage_results['accuracy'],
                        'correct': int(graphsage_results['accuracy'] * graphsage_results['test_nodes']),
                        'total': graphsage_results['test_nodes'],
                        'f1_macro': graphsage_results['f1_macro'],
                        'f1_micro': graphsage_results['f1_micro'],
                        'train_nodes': graphsage_results['train_nodes']
                    })
                else:
                    print(f"  GraphSAGEå¤±è´¥: {graphsage_results.get('message', 'æœªçŸ¥é”™è¯¯')}")
                    
            except ImportError as e:
                if hide_ratio == hide_ratios[0]:  # åªåœ¨ç¬¬ä¸€æ¬¡æ—¶æ‰“å°è­¦å‘Š
                    print(f"  âš ï¸  è·³è¿‡GraphSAGEï¼šéœ€è¦å®‰è£…PyTorch (pip install torch)")
            except Exception as e:
                print(f"  âŒ GraphSAGEå¤±è´¥: {e}")
                if hide_ratio == hide_ratios[0]:  # åªåœ¨ç¬¬ä¸€æ¬¡æ—¶æ‰“å°è¯¦ç»†é”™è¯¯
                    import traceback
                    traceback.print_exc()
        
        self.results['attribute_inference'] = results
        return results
    
    def run_robustness_test(self):
        """è¿è¡Œé²æ£’æ€§æµ‹è¯•"""
        print(f"\n{'='*70}")
        print("ã€é˜¶æ®µ3ã€‘é²æ£’æ€§æµ‹è¯•")
        print(f"{'='*70}")
        
        try:
            robustness = RobustnessSimulator(self.G)
            incomplete_ratios = [0.1, 0.2, 0.3, 0.5]
            
            # ç”Ÿæˆæ‰€æœ‰ä¸å®Œæ•´å›¾
            incomplete_graphs = robustness.generate_incomplete_graphs(incomplete_ratios)
            
            results = []
            for ratio in incomplete_ratios:
                print(f"\næµ‹è¯•ç¼ºå¤±ç‡: {ratio:.0%}")
                G_incomplete = incomplete_graphs[ratio]
                
                # ç®€å•çš„å»åŒ¿ååŒ–æµ‹è¯•
                anonymizer = GraphAnonymizer(G_incomplete)
                G_anon, mapping = anonymizer.anonymize_with_perturbation(
                    edge_retention_ratio=0.9,
                    noise_edge_ratio=0.05
                )
                
                ground_truth = {orig: mapping[orig] for orig in G_incomplete.nodes() if orig in mapping}
                
                baseline = BaselineMatcher(G_incomplete, G_anon, similarity_metric='cosine')
                predictions = baseline.match_by_features(top_k=10)
                metrics = DeAnonymizationMetrics.calculate_all_metrics(predictions, ground_truth)
                
                print(f"  - Top-1å‡†ç¡®ç‡: {metrics['accuracy']:.2%}")
                
                results.append({
                    'missing_ratio': ratio,
                    'accuracy': metrics['accuracy']
                })
            
            self.results['robustness'] = results
            return results
        except Exception as e:
            print(f"é²æ£’æ€§æµ‹è¯•å¤±è´¥: {e}")
            return []
    
    def run_defense_experiment(self, epsilon_values=None):
        """è¿è¡Œå·®åˆ†éšç§é˜²å¾¡å®éªŒ"""
        print(f"\n{'='*70}")
        print("ã€é˜¶æ®µ4ã€‘å·®åˆ†éšç§é˜²å¾¡")
        print(f"{'='*70}")
        
        if epsilon_values is None:
            epsilon_values = [0.1, 0.5, 1.0, 2.0]
        
        try:
            results = []
            for epsilon in epsilon_values:
                print(f"\næµ‹è¯• Îµ = {epsilon}")
                
                dp_defense = DifferentialPrivacyDefense(self.G, epsilon=epsilon)
                G_protected = dp_defense.add_noise_edge_perturbation()
                
                # è¯„ä¼°æ•ˆç”¨ä¿æŒ
                evaluator = PrivacyUtilityEvaluator(self.G, G_protected)
                structural_loss = evaluator.calculate_graph_structural_loss()
                
                # è®¡ç®—æ•ˆç”¨ä¿æŒç‡ï¼ˆ1 - æŸå¤±ï¼‰
                edge_preservation = structural_loss['edges_unchanged'] / self.G.number_of_edges() if self.G.number_of_edges() > 0 else 0
                utility_score = 1 - structural_loss['l1_distance']  # åŸºäºL1è·ç¦»çš„æ•ˆç”¨å¾—åˆ†
                
                print(f"  - èŠ‚ç‚¹æ•°: {G_protected.number_of_nodes()}")
                print(f"  - è¾¹æ•°: {G_protected.number_of_edges()}")
                print(f"  - è¾¹ä¿ç•™ç‡: {edge_preservation:.2%}")
                print(f"  - æ•ˆç”¨å¾—åˆ†: {utility_score:.2%}")
                print(f"  - åº¦åˆ†å¸ƒMAE: {structural_loss['degree_mae']:.2f}")
                
                results.append({
                    'epsilon': epsilon,
                    'protected_nodes': G_protected.number_of_nodes(),
                    'protected_edges': G_protected.number_of_edges(),
                    'edge_preservation': edge_preservation,
                    'utility_score': utility_score,
                    'structural_loss': structural_loss
                })
            
            self.results['defense'] = results
            return results
        except Exception as e:
            print(f"é˜²å¾¡å®éªŒå¤±è´¥: {e}")
            return []
    
    def print_summary(self):
        """æ‰“å°å®éªŒæ€»ç»“"""
        print(f"\n{'='*70}")
        print("å®éªŒç»“æœæ€»ç»“")
        print(f"{'='*70}")
        
        # å»åŒ¿ååŒ–ç»“æœ
        if 'deanonymization' in self.results:
            print(f"\nã€èº«ä»½å»åŒ¿ååŒ–ç»“æœã€‘")
            print(f"{'åŒ¿ååŒ–å¼ºåº¦':<12} {'æ–¹æ³•':<20} {'Top-1':<8} {'P@5':<8} {'MRR':<8}")
            print("-"*60)
            for r in self.results['deanonymization']:
                print(f"{r['level']:<12} {r['method']:<20} "
                      f"{r['accuracy']:>6.2%} {r.get('precision@5', 0):>6.2%} {r.get('mrr', 0):>6.4f}")
        
        # å±æ€§æ¨æ–­ç»“æœ
        if 'attribute_inference' in self.results:
            print(f"\nã€å±æ€§æ¨æ–­ç»“æœã€‘")
            print(f"{'éšè—æ¯”ä¾‹':<12} {'æ–¹æ³•':<20} {'å‡†ç¡®ç‡':<10}")
            print("-"*45)
            for r in self.results['attribute_inference']:
                print(f"{r['hide_ratio']:<12.0%} {r['method']:<20} {r['accuracy']:>8.2%}")
        
        # é²æ£’æ€§ç»“æœ
        if 'robustness' in self.results:
            print(f"\nã€é²æ£’æ€§æµ‹è¯•ç»“æœã€‘")
            print(f"{'ç¼ºå¤±ç‡':<12} {'å‡†ç¡®ç‡':<10}")
            print("-"*25)
            for r in self.results['robustness']:
                print(f"{r['missing_ratio']:<12.0%} {r['accuracy']:>8.2%}")
        
        # é˜²å¾¡ç»“æœ
        if 'defense' in self.results:
            print(f"\nã€å·®åˆ†éšç§é˜²å¾¡ç»“æœã€‘")
            print(f"{'Epsilon':<12} {'è¾¹ä¿ç•™ç‡':<12} {'æ•ˆç”¨å¾—åˆ†':<12}")
            print("-"*40)
            for r in self.results['defense']:
                edge_pres = r.get('edge_preservation', 0)
                utility = r.get('utility_score', 0)
                print(f"{r['epsilon']:<12.2f} {edge_pres:>10.2%} {utility:>10.2%}")
    
    def save_results(self):
        """ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{self.dataset_name}"
        if self.ego_id:
            filename += f"_ego{self.ego_id}"
        filename += f"_{timestamp}.json"
        
        filepath = os.path.join(self.output_dir, filename)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        return filepath


def main():
    parser = argparse.ArgumentParser(
        description="ç»Ÿä¸€å®éªŒæ¡†æ¶ - æ”¯æŒæ‰€æœ‰æ•°æ®é›†å’Œæ‰€æœ‰å®éªŒæ¨¡å¼"
    )
    
    # æ•°æ®é›†å‚æ•°
    parser.add_argument(
        '--dataset',
        type=str,
        required=True,
        choices=['facebook', 'facebook_ego', 'cora', 'citeseer', 'weibo'],
        help='æ•°æ®é›†åç§°'
    )
    parser.add_argument(
        '--ego_id',
        type=str,
        default='0',
        help='Egoç½‘ç»œID (ä»…ç”¨äºfacebook_ego)'
    )
    
    # å®éªŒæ¨¡å¼
    parser.add_argument(
        '--mode',
        type=str,
        default='attack',
        choices=['quick', 'attack', 'attribute', 'robustness', 'defense', 'all'],
        help='å®éªŒæ¨¡å¼: quick(å¿«é€Ÿ), attack(å»åŒ¿ååŒ–), attribute(å±æ€§æ¨æ–­), robustness(é²æ£’æ€§), defense(é˜²å¾¡), all(å…¨éƒ¨)'
    )
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument(
        '--output',
        type=str,
        default='results/unified',
        help='è¾“å‡ºç›®å½•'
    )
    
    parser.add_argument(
        '--save',
        action='store_true',
        default=True,
        help='ä¿å­˜ç»“æœåˆ°JSONæ–‡ä»¶ï¼ˆé»˜è®¤å¼€å¯ï¼‰'
    )
    
    parser.add_argument(
        '--no-save',
        dest='save',
        action='store_false',
        help='ä¸ä¿å­˜ç»“æœï¼ˆä»…ç»ˆç«¯æ˜¾ç¤ºï¼‰'
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºå®éªŒ
    experiment = UnifiedExperiment(
        dataset_name=args.dataset,
        ego_id=args.ego_id if args.dataset == 'facebook_ego' else None,
        output_dir=args.output
    )
    
    # æ‰“å°æ•°æ®é›†ä¿¡æ¯
    experiment.print_dataset_info()
    
    # æ ¹æ®æ¨¡å¼è¿è¡Œå®éªŒ
    if args.mode == 'quick':
        # å¿«é€Ÿæµ‹è¯•ï¼šåªæµ‹è¯•ä¸€ç§åŒ¿ååŒ–å¼ºåº¦
        experiment.run_deanonymization_attack(
            anonymization_levels=[(0.95, 0.02, "æ¸©å’Œ")]
        )
    
    elif args.mode == 'attack':
        # å®Œæ•´å»åŒ¿ååŒ–æ”»å‡»
        experiment.run_deanonymization_attack()
    
    elif args.mode == 'attribute':
        # å±æ€§æ¨æ–­
        experiment.run_attribute_inference()
    
    elif args.mode == 'robustness':
        # é²æ£’æ€§æµ‹è¯•
        experiment.run_robustness_test()
    
    elif args.mode == 'defense':
        # å·®åˆ†éšç§é˜²å¾¡
        experiment.run_defense_experiment()
    
    elif args.mode == 'all':
        # å®Œæ•´å®éªŒ
        experiment.run_deanonymization_attack()
        experiment.run_attribute_inference()
        experiment.run_robustness_test()
        experiment.run_defense_experiment()
    
    # æ‰“å°æ€»ç»“
    experiment.print_summary()
    
    # ä¿å­˜ç»“æœï¼ˆé»˜è®¤ä¿å­˜ï¼Œé™¤éä½¿ç”¨--no-saveï¼‰
    if args.save:
        filepath = experiment.save_results()
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {filepath}")
    else:
        print(f"\nğŸ’¡ ç»“æœæœªä¿å­˜ï¼ˆä½¿ç”¨ --no-save å‚æ•°ï¼‰")
    
    print(f"\n{'='*70}")
    print("å®éªŒå®Œæˆï¼")
    print(f"{'='*70}")


if __name__ == "__main__":
    main()


